{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.912413030756226,
  "eval_steps": 500,
  "global_step": 5600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005201898693022953,
      "grad_norm": 0.5776023268699646,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 1.5947,
      "step": 10
    },
    {
      "epoch": 0.010403797386045906,
      "grad_norm": 0.8386340141296387,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 1.7034,
      "step": 20
    },
    {
      "epoch": 0.01560569607906886,
      "grad_norm": 0.9110373854637146,
      "learning_rate": 5.8e-06,
      "loss": 1.9233,
      "step": 30
    },
    {
      "epoch": 0.020807594772091813,
      "grad_norm": 0.7149322628974915,
      "learning_rate": 7.800000000000002e-06,
      "loss": 1.8461,
      "step": 40
    },
    {
      "epoch": 0.026009493465114768,
      "grad_norm": 0.7572993040084839,
      "learning_rate": 9.800000000000001e-06,
      "loss": 1.7343,
      "step": 50
    },
    {
      "epoch": 0.03121139215813772,
      "grad_norm": 0.7005432844161987,
      "learning_rate": 1.18e-05,
      "loss": 1.8055,
      "step": 60
    },
    {
      "epoch": 0.03641329085116067,
      "grad_norm": 0.6822580695152283,
      "learning_rate": 1.38e-05,
      "loss": 1.7174,
      "step": 70
    },
    {
      "epoch": 0.041615189544183626,
      "grad_norm": 0.8675437569618225,
      "learning_rate": 1.58e-05,
      "loss": 1.8241,
      "step": 80
    },
    {
      "epoch": 0.04681708823720658,
      "grad_norm": 0.6657048463821411,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 1.6696,
      "step": 90
    },
    {
      "epoch": 0.052018986930229535,
      "grad_norm": 0.6860967874526978,
      "learning_rate": 1.98e-05,
      "loss": 1.6201,
      "step": 100
    },
    {
      "epoch": 0.05722088562325249,
      "grad_norm": 0.6348503828048706,
      "learning_rate": 1.9968231556653727e-05,
      "loss": 1.9069,
      "step": 110
    },
    {
      "epoch": 0.06242278431627544,
      "grad_norm": 0.7762742638587952,
      "learning_rate": 1.9932933286268974e-05,
      "loss": 1.9812,
      "step": 120
    },
    {
      "epoch": 0.0676246830092984,
      "grad_norm": 0.7612094283103943,
      "learning_rate": 1.9897635015884222e-05,
      "loss": 1.904,
      "step": 130
    },
    {
      "epoch": 0.07282658170232134,
      "grad_norm": 0.7370652556419373,
      "learning_rate": 1.9862336745499473e-05,
      "loss": 1.66,
      "step": 140
    },
    {
      "epoch": 0.0780284803953443,
      "grad_norm": 0.7090339064598083,
      "learning_rate": 1.982703847511472e-05,
      "loss": 1.779,
      "step": 150
    },
    {
      "epoch": 0.08323037908836725,
      "grad_norm": 1.082425832748413,
      "learning_rate": 1.979174020472997e-05,
      "loss": 1.8168,
      "step": 160
    },
    {
      "epoch": 0.0884322777813902,
      "grad_norm": 0.7296083569526672,
      "learning_rate": 1.9756441934345217e-05,
      "loss": 1.7482,
      "step": 170
    },
    {
      "epoch": 0.09363417647441316,
      "grad_norm": 0.593898594379425,
      "learning_rate": 1.9721143663960468e-05,
      "loss": 1.7356,
      "step": 180
    },
    {
      "epoch": 0.09883607516743612,
      "grad_norm": 0.7229330539703369,
      "learning_rate": 1.9685845393575716e-05,
      "loss": 1.7651,
      "step": 190
    },
    {
      "epoch": 0.10403797386045907,
      "grad_norm": 0.7585636377334595,
      "learning_rate": 1.9650547123190967e-05,
      "loss": 1.7018,
      "step": 200
    },
    {
      "epoch": 0.10923987255348203,
      "grad_norm": 0.8191906809806824,
      "learning_rate": 1.9615248852806215e-05,
      "loss": 1.6876,
      "step": 210
    },
    {
      "epoch": 0.11444177124650498,
      "grad_norm": 1.0313338041305542,
      "learning_rate": 1.9579950582421463e-05,
      "loss": 1.7335,
      "step": 220
    },
    {
      "epoch": 0.11964366993952792,
      "grad_norm": 1.313517451286316,
      "learning_rate": 1.954465231203671e-05,
      "loss": 1.7965,
      "step": 230
    },
    {
      "epoch": 0.12484556863255088,
      "grad_norm": 0.8974454998970032,
      "learning_rate": 1.950935404165196e-05,
      "loss": 1.7648,
      "step": 240
    },
    {
      "epoch": 0.13004746732557385,
      "grad_norm": 0.8146894574165344,
      "learning_rate": 1.947405577126721e-05,
      "loss": 1.6168,
      "step": 250
    },
    {
      "epoch": 0.1352493660185968,
      "grad_norm": 0.9300618767738342,
      "learning_rate": 1.943875750088246e-05,
      "loss": 1.7238,
      "step": 260
    },
    {
      "epoch": 0.14045126471161973,
      "grad_norm": 0.6849765181541443,
      "learning_rate": 1.940345923049771e-05,
      "loss": 1.8078,
      "step": 270
    },
    {
      "epoch": 0.14565316340464268,
      "grad_norm": 0.6369457840919495,
      "learning_rate": 1.9368160960112956e-05,
      "loss": 1.6567,
      "step": 280
    },
    {
      "epoch": 0.15085506209766564,
      "grad_norm": 0.8567978739738464,
      "learning_rate": 1.9332862689728204e-05,
      "loss": 1.8259,
      "step": 290
    },
    {
      "epoch": 0.1560569607906886,
      "grad_norm": 0.8007034063339233,
      "learning_rate": 1.9297564419343452e-05,
      "loss": 1.7023,
      "step": 300
    },
    {
      "epoch": 0.16125885948371155,
      "grad_norm": 0.6004815101623535,
      "learning_rate": 1.9262266148958703e-05,
      "loss": 1.6783,
      "step": 310
    },
    {
      "epoch": 0.1664607581767345,
      "grad_norm": 0.9046052694320679,
      "learning_rate": 1.922696787857395e-05,
      "loss": 1.7466,
      "step": 320
    },
    {
      "epoch": 0.17166265686975746,
      "grad_norm": 0.6452744007110596,
      "learning_rate": 1.9191669608189202e-05,
      "loss": 1.6946,
      "step": 330
    },
    {
      "epoch": 0.1768645555627804,
      "grad_norm": 0.6408897042274475,
      "learning_rate": 1.915637133780445e-05,
      "loss": 1.7064,
      "step": 340
    },
    {
      "epoch": 0.18206645425580337,
      "grad_norm": 1.209506869316101,
      "learning_rate": 1.9121073067419698e-05,
      "loss": 1.7198,
      "step": 350
    },
    {
      "epoch": 0.18726835294882632,
      "grad_norm": 0.7948242425918579,
      "learning_rate": 1.9085774797034945e-05,
      "loss": 1.6822,
      "step": 360
    },
    {
      "epoch": 0.19247025164184928,
      "grad_norm": 0.758524477481842,
      "learning_rate": 1.9050476526650197e-05,
      "loss": 1.7633,
      "step": 370
    },
    {
      "epoch": 0.19767215033487223,
      "grad_norm": 0.6671103835105896,
      "learning_rate": 1.9015178256265444e-05,
      "loss": 1.7113,
      "step": 380
    },
    {
      "epoch": 0.2028740490278952,
      "grad_norm": 0.7451679110527039,
      "learning_rate": 1.8979879985880692e-05,
      "loss": 1.622,
      "step": 390
    },
    {
      "epoch": 0.20807594772091814,
      "grad_norm": 0.7317479848861694,
      "learning_rate": 1.8944581715495943e-05,
      "loss": 1.6771,
      "step": 400
    },
    {
      "epoch": 0.2132778464139411,
      "grad_norm": 0.8262038826942444,
      "learning_rate": 1.890928344511119e-05,
      "loss": 1.7385,
      "step": 410
    },
    {
      "epoch": 0.21847974510696405,
      "grad_norm": 1.0667279958724976,
      "learning_rate": 1.887398517472644e-05,
      "loss": 1.6389,
      "step": 420
    },
    {
      "epoch": 0.223681643799987,
      "grad_norm": 0.664322018623352,
      "learning_rate": 1.883868690434169e-05,
      "loss": 1.5861,
      "step": 430
    },
    {
      "epoch": 0.22888354249300996,
      "grad_norm": 1.0270289182662964,
      "learning_rate": 1.8803388633956938e-05,
      "loss": 1.6392,
      "step": 440
    },
    {
      "epoch": 0.2340854411860329,
      "grad_norm": 0.8971045613288879,
      "learning_rate": 1.8768090363572186e-05,
      "loss": 1.7373,
      "step": 450
    },
    {
      "epoch": 0.23928733987905584,
      "grad_norm": 0.7316034436225891,
      "learning_rate": 1.8732792093187434e-05,
      "loss": 1.6846,
      "step": 460
    },
    {
      "epoch": 0.2444892385720788,
      "grad_norm": 0.6617230176925659,
      "learning_rate": 1.8697493822802685e-05,
      "loss": 1.8289,
      "step": 470
    },
    {
      "epoch": 0.24969113726510175,
      "grad_norm": 0.8436936736106873,
      "learning_rate": 1.8662195552417933e-05,
      "loss": 1.7729,
      "step": 480
    },
    {
      "epoch": 0.25489303595812474,
      "grad_norm": 0.7563367486000061,
      "learning_rate": 1.8626897282033184e-05,
      "loss": 1.634,
      "step": 490
    },
    {
      "epoch": 0.2600949346511477,
      "grad_norm": 1.0209403038024902,
      "learning_rate": 1.859159901164843e-05,
      "loss": 1.7741,
      "step": 500
    },
    {
      "epoch": 0.26529683334417065,
      "grad_norm": 0.9016430377960205,
      "learning_rate": 1.855630074126368e-05,
      "loss": 1.6758,
      "step": 510
    },
    {
      "epoch": 0.2704987320371936,
      "grad_norm": 0.8174135088920593,
      "learning_rate": 1.8521002470878927e-05,
      "loss": 1.7362,
      "step": 520
    },
    {
      "epoch": 0.27570063073021656,
      "grad_norm": 0.8603700399398804,
      "learning_rate": 1.848570420049418e-05,
      "loss": 1.6589,
      "step": 530
    },
    {
      "epoch": 0.28090252942323946,
      "grad_norm": 0.8179397583007812,
      "learning_rate": 1.8450405930109426e-05,
      "loss": 1.5743,
      "step": 540
    },
    {
      "epoch": 0.2861044281162624,
      "grad_norm": 0.6566049456596375,
      "learning_rate": 1.8415107659724677e-05,
      "loss": 1.7287,
      "step": 550
    },
    {
      "epoch": 0.29130632680928537,
      "grad_norm": 0.6356648802757263,
      "learning_rate": 1.8379809389339925e-05,
      "loss": 1.7808,
      "step": 560
    },
    {
      "epoch": 0.2965082255023083,
      "grad_norm": 0.6666675209999084,
      "learning_rate": 1.8344511118955173e-05,
      "loss": 1.6851,
      "step": 570
    },
    {
      "epoch": 0.3017101241953313,
      "grad_norm": 0.6496979594230652,
      "learning_rate": 1.830921284857042e-05,
      "loss": 1.7295,
      "step": 580
    },
    {
      "epoch": 0.30691202288835423,
      "grad_norm": 0.8159669041633606,
      "learning_rate": 1.827391457818567e-05,
      "loss": 1.7036,
      "step": 590
    },
    {
      "epoch": 0.3121139215813772,
      "grad_norm": 0.7371938228607178,
      "learning_rate": 1.823861630780092e-05,
      "loss": 1.6099,
      "step": 600
    },
    {
      "epoch": 0.31731582027440014,
      "grad_norm": 0.7857899069786072,
      "learning_rate": 1.8203318037416168e-05,
      "loss": 1.8007,
      "step": 610
    },
    {
      "epoch": 0.3225177189674231,
      "grad_norm": 1.0287854671478271,
      "learning_rate": 1.816801976703142e-05,
      "loss": 1.7227,
      "step": 620
    },
    {
      "epoch": 0.32771961766044605,
      "grad_norm": 0.789644181728363,
      "learning_rate": 1.8132721496646667e-05,
      "loss": 1.6271,
      "step": 630
    },
    {
      "epoch": 0.332921516353469,
      "grad_norm": 0.8935343027114868,
      "learning_rate": 1.8097423226261914e-05,
      "loss": 1.682,
      "step": 640
    },
    {
      "epoch": 0.33812341504649196,
      "grad_norm": 0.8380886912345886,
      "learning_rate": 1.8062124955877162e-05,
      "loss": 1.7096,
      "step": 650
    },
    {
      "epoch": 0.3433253137395149,
      "grad_norm": 1.355087399482727,
      "learning_rate": 1.8026826685492413e-05,
      "loss": 1.6814,
      "step": 660
    },
    {
      "epoch": 0.34852721243253787,
      "grad_norm": 0.6974168419837952,
      "learning_rate": 1.799152841510766e-05,
      "loss": 1.6398,
      "step": 670
    },
    {
      "epoch": 0.3537291111255608,
      "grad_norm": 1.1792924404144287,
      "learning_rate": 1.795623014472291e-05,
      "loss": 1.6992,
      "step": 680
    },
    {
      "epoch": 0.3589310098185838,
      "grad_norm": 0.8855296969413757,
      "learning_rate": 1.792093187433816e-05,
      "loss": 1.6453,
      "step": 690
    },
    {
      "epoch": 0.36413290851160673,
      "grad_norm": 0.6758591532707214,
      "learning_rate": 1.7885633603953408e-05,
      "loss": 1.7389,
      "step": 700
    },
    {
      "epoch": 0.3693348072046297,
      "grad_norm": 0.8154648542404175,
      "learning_rate": 1.7850335333568656e-05,
      "loss": 1.5838,
      "step": 710
    },
    {
      "epoch": 0.37453670589765264,
      "grad_norm": 0.6794300079345703,
      "learning_rate": 1.7815037063183907e-05,
      "loss": 1.7368,
      "step": 720
    },
    {
      "epoch": 0.3797386045906756,
      "grad_norm": 0.7765898108482361,
      "learning_rate": 1.7779738792799155e-05,
      "loss": 1.7139,
      "step": 730
    },
    {
      "epoch": 0.38494050328369855,
      "grad_norm": 0.9682345390319824,
      "learning_rate": 1.7744440522414403e-05,
      "loss": 1.7155,
      "step": 740
    },
    {
      "epoch": 0.3901424019767215,
      "grad_norm": 0.713361918926239,
      "learning_rate": 1.770914225202965e-05,
      "loss": 1.7913,
      "step": 750
    },
    {
      "epoch": 0.39534430066974446,
      "grad_norm": 0.9695414304733276,
      "learning_rate": 1.76738439816449e-05,
      "loss": 1.7363,
      "step": 760
    },
    {
      "epoch": 0.4005461993627674,
      "grad_norm": 0.7607024312019348,
      "learning_rate": 1.763854571126015e-05,
      "loss": 1.6973,
      "step": 770
    },
    {
      "epoch": 0.4057480980557904,
      "grad_norm": 0.7571276426315308,
      "learning_rate": 1.76032474408754e-05,
      "loss": 1.7694,
      "step": 780
    },
    {
      "epoch": 0.41094999674881333,
      "grad_norm": 0.7629024386405945,
      "learning_rate": 1.756794917049065e-05,
      "loss": 1.5867,
      "step": 790
    },
    {
      "epoch": 0.4161518954418363,
      "grad_norm": 0.9361771941184998,
      "learning_rate": 1.7532650900105896e-05,
      "loss": 1.7081,
      "step": 800
    },
    {
      "epoch": 0.42135379413485924,
      "grad_norm": 0.7410680055618286,
      "learning_rate": 1.7497352629721144e-05,
      "loss": 1.5863,
      "step": 810
    },
    {
      "epoch": 0.4265556928278822,
      "grad_norm": 1.0750080347061157,
      "learning_rate": 1.7462054359336392e-05,
      "loss": 1.7191,
      "step": 820
    },
    {
      "epoch": 0.43175759152090515,
      "grad_norm": 0.672770082950592,
      "learning_rate": 1.7426756088951643e-05,
      "loss": 1.7562,
      "step": 830
    },
    {
      "epoch": 0.4369594902139281,
      "grad_norm": 0.9033048152923584,
      "learning_rate": 1.7391457818566894e-05,
      "loss": 1.7166,
      "step": 840
    },
    {
      "epoch": 0.44216138890695106,
      "grad_norm": 0.7830987572669983,
      "learning_rate": 1.7356159548182142e-05,
      "loss": 1.7366,
      "step": 850
    },
    {
      "epoch": 0.447363287599974,
      "grad_norm": 0.7962011098861694,
      "learning_rate": 1.732086127779739e-05,
      "loss": 1.5823,
      "step": 860
    },
    {
      "epoch": 0.45256518629299697,
      "grad_norm": 0.6902860999107361,
      "learning_rate": 1.7285563007412637e-05,
      "loss": 1.7403,
      "step": 870
    },
    {
      "epoch": 0.4577670849860199,
      "grad_norm": 0.7143266201019287,
      "learning_rate": 1.7250264737027885e-05,
      "loss": 1.7504,
      "step": 880
    },
    {
      "epoch": 0.4629689836790429,
      "grad_norm": 0.8715184926986694,
      "learning_rate": 1.7214966466643136e-05,
      "loss": 1.6593,
      "step": 890
    },
    {
      "epoch": 0.4681708823720658,
      "grad_norm": 0.8210904002189636,
      "learning_rate": 1.7179668196258384e-05,
      "loss": 1.5997,
      "step": 900
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.9415479302406311,
      "learning_rate": 1.7144369925873635e-05,
      "loss": 1.6929,
      "step": 910
    },
    {
      "epoch": 0.4785746797581117,
      "grad_norm": 0.5289322733879089,
      "learning_rate": 1.7109071655488883e-05,
      "loss": 1.6024,
      "step": 920
    },
    {
      "epoch": 0.48377657845113464,
      "grad_norm": 0.7853404879570007,
      "learning_rate": 1.707377338510413e-05,
      "loss": 1.7043,
      "step": 930
    },
    {
      "epoch": 0.4889784771441576,
      "grad_norm": 0.8178333044052124,
      "learning_rate": 1.703847511471938e-05,
      "loss": 1.6114,
      "step": 940
    },
    {
      "epoch": 0.49418037583718055,
      "grad_norm": 0.7863826155662537,
      "learning_rate": 1.7003176844334627e-05,
      "loss": 1.6703,
      "step": 950
    },
    {
      "epoch": 0.4993822745302035,
      "grad_norm": 0.9740515351295471,
      "learning_rate": 1.6967878573949878e-05,
      "loss": 1.75,
      "step": 960
    },
    {
      "epoch": 0.5045841732232265,
      "grad_norm": 0.8903657793998718,
      "learning_rate": 1.6932580303565126e-05,
      "loss": 1.7492,
      "step": 970
    },
    {
      "epoch": 0.5097860719162495,
      "grad_norm": 0.607168436050415,
      "learning_rate": 1.6897282033180377e-05,
      "loss": 1.6024,
      "step": 980
    },
    {
      "epoch": 0.5149879706092724,
      "grad_norm": 0.8156880140304565,
      "learning_rate": 1.6861983762795625e-05,
      "loss": 1.7215,
      "step": 990
    },
    {
      "epoch": 0.5201898693022954,
      "grad_norm": 0.6352478265762329,
      "learning_rate": 1.6826685492410872e-05,
      "loss": 1.667,
      "step": 1000
    },
    {
      "epoch": 0.5253917679953183,
      "grad_norm": 0.8184834122657776,
      "learning_rate": 1.6791387222026124e-05,
      "loss": 1.6195,
      "step": 1010
    },
    {
      "epoch": 0.5305936666883413,
      "grad_norm": 0.8346952199935913,
      "learning_rate": 1.675608895164137e-05,
      "loss": 1.7001,
      "step": 1020
    },
    {
      "epoch": 0.5357955653813642,
      "grad_norm": 0.8661733269691467,
      "learning_rate": 1.672079068125662e-05,
      "loss": 1.6256,
      "step": 1030
    },
    {
      "epoch": 0.5409974640743872,
      "grad_norm": 0.9295213222503662,
      "learning_rate": 1.6685492410871867e-05,
      "loss": 1.6935,
      "step": 1040
    },
    {
      "epoch": 0.5461993627674101,
      "grad_norm": 0.7275731563568115,
      "learning_rate": 1.6650194140487118e-05,
      "loss": 1.7189,
      "step": 1050
    },
    {
      "epoch": 0.5514012614604331,
      "grad_norm": 0.7695444226264954,
      "learning_rate": 1.6614895870102366e-05,
      "loss": 1.6801,
      "step": 1060
    },
    {
      "epoch": 0.556603160153456,
      "grad_norm": 0.7990497946739197,
      "learning_rate": 1.6579597599717617e-05,
      "loss": 1.6793,
      "step": 1070
    },
    {
      "epoch": 0.5618050588464789,
      "grad_norm": 0.8036233186721802,
      "learning_rate": 1.6544299329332865e-05,
      "loss": 1.5925,
      "step": 1080
    },
    {
      "epoch": 0.5670069575395019,
      "grad_norm": 0.6980953812599182,
      "learning_rate": 1.6509001058948113e-05,
      "loss": 1.6705,
      "step": 1090
    },
    {
      "epoch": 0.5722088562325248,
      "grad_norm": 0.6272998452186584,
      "learning_rate": 1.647370278856336e-05,
      "loss": 1.6528,
      "step": 1100
    },
    {
      "epoch": 0.5774107549255478,
      "grad_norm": 0.7613925933837891,
      "learning_rate": 1.643840451817861e-05,
      "loss": 1.6906,
      "step": 1110
    },
    {
      "epoch": 0.5826126536185707,
      "grad_norm": 0.8475329875946045,
      "learning_rate": 1.640310624779386e-05,
      "loss": 1.8042,
      "step": 1120
    },
    {
      "epoch": 0.5878145523115937,
      "grad_norm": 0.6803136467933655,
      "learning_rate": 1.636780797740911e-05,
      "loss": 1.8051,
      "step": 1130
    },
    {
      "epoch": 0.5930164510046166,
      "grad_norm": 0.7264716625213623,
      "learning_rate": 1.633250970702436e-05,
      "loss": 1.7223,
      "step": 1140
    },
    {
      "epoch": 0.5982183496976397,
      "grad_norm": 0.8676854372024536,
      "learning_rate": 1.6297211436639606e-05,
      "loss": 1.8053,
      "step": 1150
    },
    {
      "epoch": 0.6034202483906626,
      "grad_norm": 0.6242063045501709,
      "learning_rate": 1.6261913166254854e-05,
      "loss": 1.7608,
      "step": 1160
    },
    {
      "epoch": 0.6086221470836856,
      "grad_norm": 0.9038029313087463,
      "learning_rate": 1.6226614895870102e-05,
      "loss": 1.6623,
      "step": 1170
    },
    {
      "epoch": 0.6138240457767085,
      "grad_norm": 0.8199548125267029,
      "learning_rate": 1.6191316625485353e-05,
      "loss": 1.6648,
      "step": 1180
    },
    {
      "epoch": 0.6190259444697315,
      "grad_norm": 0.7105662226676941,
      "learning_rate": 1.61560183551006e-05,
      "loss": 1.694,
      "step": 1190
    },
    {
      "epoch": 0.6242278431627544,
      "grad_norm": 0.7305186986923218,
      "learning_rate": 1.6120720084715852e-05,
      "loss": 1.6476,
      "step": 1200
    },
    {
      "epoch": 0.6294297418557774,
      "grad_norm": 0.6472436189651489,
      "learning_rate": 1.60854218143311e-05,
      "loss": 1.6566,
      "step": 1210
    },
    {
      "epoch": 0.6346316405488003,
      "grad_norm": 0.7638018131256104,
      "learning_rate": 1.6050123543946348e-05,
      "loss": 1.693,
      "step": 1220
    },
    {
      "epoch": 0.6398335392418233,
      "grad_norm": 0.7804917097091675,
      "learning_rate": 1.6014825273561596e-05,
      "loss": 1.7412,
      "step": 1230
    },
    {
      "epoch": 0.6450354379348462,
      "grad_norm": 0.6508166790008545,
      "learning_rate": 1.5979527003176843e-05,
      "loss": 1.7133,
      "step": 1240
    },
    {
      "epoch": 0.6502373366278692,
      "grad_norm": 0.7090149521827698,
      "learning_rate": 1.5944228732792095e-05,
      "loss": 1.6526,
      "step": 1250
    },
    {
      "epoch": 0.6554392353208921,
      "grad_norm": 0.9405190944671631,
      "learning_rate": 1.5908930462407342e-05,
      "loss": 1.6722,
      "step": 1260
    },
    {
      "epoch": 0.6606411340139151,
      "grad_norm": 0.9875858426094055,
      "learning_rate": 1.5873632192022594e-05,
      "loss": 1.586,
      "step": 1270
    },
    {
      "epoch": 0.665843032706938,
      "grad_norm": 0.5421526432037354,
      "learning_rate": 1.583833392163784e-05,
      "loss": 1.695,
      "step": 1280
    },
    {
      "epoch": 0.671044931399961,
      "grad_norm": 1.0571632385253906,
      "learning_rate": 1.580303565125309e-05,
      "loss": 1.6781,
      "step": 1290
    },
    {
      "epoch": 0.6762468300929839,
      "grad_norm": 0.7344601154327393,
      "learning_rate": 1.576773738086834e-05,
      "loss": 1.7475,
      "step": 1300
    },
    {
      "epoch": 0.6814487287860069,
      "grad_norm": 0.6211495399475098,
      "learning_rate": 1.5732439110483588e-05,
      "loss": 1.6667,
      "step": 1310
    },
    {
      "epoch": 0.6866506274790298,
      "grad_norm": 0.6742249727249146,
      "learning_rate": 1.5697140840098836e-05,
      "loss": 1.6858,
      "step": 1320
    },
    {
      "epoch": 0.6918525261720528,
      "grad_norm": 0.8114238977432251,
      "learning_rate": 1.5661842569714084e-05,
      "loss": 1.6121,
      "step": 1330
    },
    {
      "epoch": 0.6970544248650757,
      "grad_norm": 1.4698777198791504,
      "learning_rate": 1.5626544299329335e-05,
      "loss": 1.8198,
      "step": 1340
    },
    {
      "epoch": 0.7022563235580987,
      "grad_norm": 0.7685519456863403,
      "learning_rate": 1.5591246028944583e-05,
      "loss": 1.6943,
      "step": 1350
    },
    {
      "epoch": 0.7074582222511216,
      "grad_norm": 0.7947100400924683,
      "learning_rate": 1.5555947758559834e-05,
      "loss": 1.7015,
      "step": 1360
    },
    {
      "epoch": 0.7126601209441447,
      "grad_norm": 0.8158047795295715,
      "learning_rate": 1.5520649488175082e-05,
      "loss": 1.7076,
      "step": 1370
    },
    {
      "epoch": 0.7178620196371676,
      "grad_norm": 0.8237069249153137,
      "learning_rate": 1.548535121779033e-05,
      "loss": 1.7349,
      "step": 1380
    },
    {
      "epoch": 0.7230639183301906,
      "grad_norm": 0.9124174118041992,
      "learning_rate": 1.5450052947405577e-05,
      "loss": 1.6454,
      "step": 1390
    },
    {
      "epoch": 0.7282658170232135,
      "grad_norm": 0.7804911136627197,
      "learning_rate": 1.5414754677020825e-05,
      "loss": 1.7441,
      "step": 1400
    },
    {
      "epoch": 0.7334677157162365,
      "grad_norm": 0.8278619647026062,
      "learning_rate": 1.5379456406636076e-05,
      "loss": 1.6788,
      "step": 1410
    },
    {
      "epoch": 0.7386696144092594,
      "grad_norm": 1.1193230152130127,
      "learning_rate": 1.5344158136251328e-05,
      "loss": 1.741,
      "step": 1420
    },
    {
      "epoch": 0.7438715131022823,
      "grad_norm": 0.8081114888191223,
      "learning_rate": 1.5308859865866575e-05,
      "loss": 1.7028,
      "step": 1430
    },
    {
      "epoch": 0.7490734117953053,
      "grad_norm": 0.7196266651153564,
      "learning_rate": 1.5273561595481823e-05,
      "loss": 1.5381,
      "step": 1440
    },
    {
      "epoch": 0.7542753104883282,
      "grad_norm": 1.0171741247177124,
      "learning_rate": 1.5238263325097071e-05,
      "loss": 1.6045,
      "step": 1450
    },
    {
      "epoch": 0.7594772091813512,
      "grad_norm": 0.6428143382072449,
      "learning_rate": 1.520296505471232e-05,
      "loss": 1.701,
      "step": 1460
    },
    {
      "epoch": 0.7646791078743741,
      "grad_norm": 0.7172663807868958,
      "learning_rate": 1.5167666784327568e-05,
      "loss": 1.6176,
      "step": 1470
    },
    {
      "epoch": 0.7698810065673971,
      "grad_norm": 0.8109200596809387,
      "learning_rate": 1.513236851394282e-05,
      "loss": 1.7308,
      "step": 1480
    },
    {
      "epoch": 0.77508290526042,
      "grad_norm": 0.7487462162971497,
      "learning_rate": 1.5097070243558067e-05,
      "loss": 1.5509,
      "step": 1490
    },
    {
      "epoch": 0.780284803953443,
      "grad_norm": 0.653874933719635,
      "learning_rate": 1.5061771973173315e-05,
      "loss": 1.671,
      "step": 1500
    },
    {
      "epoch": 0.7854867026464659,
      "grad_norm": 0.7068713903427124,
      "learning_rate": 1.5026473702788565e-05,
      "loss": 1.7742,
      "step": 1510
    },
    {
      "epoch": 0.7906886013394889,
      "grad_norm": 0.7250952124595642,
      "learning_rate": 1.4991175432403812e-05,
      "loss": 1.6656,
      "step": 1520
    },
    {
      "epoch": 0.7958905000325118,
      "grad_norm": 0.7370692491531372,
      "learning_rate": 1.4955877162019062e-05,
      "loss": 1.704,
      "step": 1530
    },
    {
      "epoch": 0.8010923987255348,
      "grad_norm": 0.6918063759803772,
      "learning_rate": 1.4920578891634311e-05,
      "loss": 1.5936,
      "step": 1540
    },
    {
      "epoch": 0.8062942974185577,
      "grad_norm": 0.713310956954956,
      "learning_rate": 1.488528062124956e-05,
      "loss": 1.6215,
      "step": 1550
    },
    {
      "epoch": 0.8114961961115807,
      "grad_norm": 0.7895134687423706,
      "learning_rate": 1.4849982350864809e-05,
      "loss": 1.6364,
      "step": 1560
    },
    {
      "epoch": 0.8166980948046036,
      "grad_norm": 0.7152870893478394,
      "learning_rate": 1.4814684080480058e-05,
      "loss": 1.6539,
      "step": 1570
    },
    {
      "epoch": 0.8218999934976267,
      "grad_norm": 0.6427799463272095,
      "learning_rate": 1.4779385810095306e-05,
      "loss": 1.6776,
      "step": 1580
    },
    {
      "epoch": 0.8271018921906496,
      "grad_norm": 0.6698857545852661,
      "learning_rate": 1.4744087539710554e-05,
      "loss": 1.628,
      "step": 1590
    },
    {
      "epoch": 0.8323037908836726,
      "grad_norm": 0.6346940398216248,
      "learning_rate": 1.4708789269325805e-05,
      "loss": 1.6173,
      "step": 1600
    },
    {
      "epoch": 0.8375056895766955,
      "grad_norm": 0.7076190114021301,
      "learning_rate": 1.4673490998941053e-05,
      "loss": 1.7129,
      "step": 1610
    },
    {
      "epoch": 0.8427075882697185,
      "grad_norm": 0.6568821668624878,
      "learning_rate": 1.4638192728556302e-05,
      "loss": 1.6732,
      "step": 1620
    },
    {
      "epoch": 0.8479094869627414,
      "grad_norm": 0.7629791498184204,
      "learning_rate": 1.460289445817155e-05,
      "loss": 1.6571,
      "step": 1630
    },
    {
      "epoch": 0.8531113856557644,
      "grad_norm": 0.6705990433692932,
      "learning_rate": 1.45675961877868e-05,
      "loss": 1.7247,
      "step": 1640
    },
    {
      "epoch": 0.8583132843487873,
      "grad_norm": 0.925489604473114,
      "learning_rate": 1.4532297917402049e-05,
      "loss": 1.8027,
      "step": 1650
    },
    {
      "epoch": 0.8635151830418103,
      "grad_norm": 0.7675411105155945,
      "learning_rate": 1.4496999647017298e-05,
      "loss": 1.6424,
      "step": 1660
    },
    {
      "epoch": 0.8687170817348332,
      "grad_norm": 1.0975302457809448,
      "learning_rate": 1.4461701376632546e-05,
      "loss": 1.587,
      "step": 1670
    },
    {
      "epoch": 0.8739189804278562,
      "grad_norm": 0.8196133971214294,
      "learning_rate": 1.4426403106247796e-05,
      "loss": 1.6487,
      "step": 1680
    },
    {
      "epoch": 0.8791208791208791,
      "grad_norm": 0.8613862991333008,
      "learning_rate": 1.4391104835863044e-05,
      "loss": 1.5301,
      "step": 1690
    },
    {
      "epoch": 0.8843227778139021,
      "grad_norm": 0.6850190758705139,
      "learning_rate": 1.4355806565478291e-05,
      "loss": 1.6304,
      "step": 1700
    },
    {
      "epoch": 0.889524676506925,
      "grad_norm": 0.7374817728996277,
      "learning_rate": 1.4320508295093543e-05,
      "loss": 1.6519,
      "step": 1710
    },
    {
      "epoch": 0.894726575199948,
      "grad_norm": 0.6894000768661499,
      "learning_rate": 1.428521002470879e-05,
      "loss": 1.5393,
      "step": 1720
    },
    {
      "epoch": 0.8999284738929709,
      "grad_norm": 1.1828776597976685,
      "learning_rate": 1.424991175432404e-05,
      "loss": 1.6761,
      "step": 1730
    },
    {
      "epoch": 0.9051303725859939,
      "grad_norm": 0.6494778394699097,
      "learning_rate": 1.4214613483939288e-05,
      "loss": 1.6422,
      "step": 1740
    },
    {
      "epoch": 0.9103322712790168,
      "grad_norm": 0.7417954206466675,
      "learning_rate": 1.4179315213554537e-05,
      "loss": 1.7041,
      "step": 1750
    },
    {
      "epoch": 0.9155341699720398,
      "grad_norm": 0.9860506653785706,
      "learning_rate": 1.4144016943169785e-05,
      "loss": 1.6326,
      "step": 1760
    },
    {
      "epoch": 0.9207360686650627,
      "grad_norm": 0.8496993780136108,
      "learning_rate": 1.4108718672785036e-05,
      "loss": 1.6157,
      "step": 1770
    },
    {
      "epoch": 0.9259379673580858,
      "grad_norm": 0.7151255011558533,
      "learning_rate": 1.4073420402400284e-05,
      "loss": 1.7605,
      "step": 1780
    },
    {
      "epoch": 0.9311398660511087,
      "grad_norm": 0.6543370485305786,
      "learning_rate": 1.4038122132015532e-05,
      "loss": 1.6016,
      "step": 1790
    },
    {
      "epoch": 0.9363417647441316,
      "grad_norm": 0.6593953967094421,
      "learning_rate": 1.4002823861630781e-05,
      "loss": 1.6654,
      "step": 1800
    },
    {
      "epoch": 0.9415436634371546,
      "grad_norm": 0.5887600183486938,
      "learning_rate": 1.3967525591246029e-05,
      "loss": 1.7865,
      "step": 1810
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.669153094291687,
      "learning_rate": 1.3932227320861279e-05,
      "loss": 1.7335,
      "step": 1820
    },
    {
      "epoch": 0.9519474608232005,
      "grad_norm": 0.8491368293762207,
      "learning_rate": 1.3896929050476528e-05,
      "loss": 1.6763,
      "step": 1830
    },
    {
      "epoch": 0.9571493595162234,
      "grad_norm": 0.7613511085510254,
      "learning_rate": 1.3861630780091778e-05,
      "loss": 1.6388,
      "step": 1840
    },
    {
      "epoch": 0.9623512582092464,
      "grad_norm": 0.7265649437904358,
      "learning_rate": 1.3826332509707025e-05,
      "loss": 1.7393,
      "step": 1850
    },
    {
      "epoch": 0.9675531569022693,
      "grad_norm": 0.8960810303688049,
      "learning_rate": 1.3791034239322275e-05,
      "loss": 1.6343,
      "step": 1860
    },
    {
      "epoch": 0.9727550555952923,
      "grad_norm": 0.9937914609909058,
      "learning_rate": 1.3755735968937523e-05,
      "loss": 1.6786,
      "step": 1870
    },
    {
      "epoch": 0.9779569542883152,
      "grad_norm": 0.6559291481971741,
      "learning_rate": 1.372043769855277e-05,
      "loss": 1.5448,
      "step": 1880
    },
    {
      "epoch": 0.9831588529813382,
      "grad_norm": 0.7176123857498169,
      "learning_rate": 1.3685139428168022e-05,
      "loss": 1.6629,
      "step": 1890
    },
    {
      "epoch": 0.9883607516743611,
      "grad_norm": 0.5635209679603577,
      "learning_rate": 1.364984115778327e-05,
      "loss": 1.634,
      "step": 1900
    },
    {
      "epoch": 0.9935626503673841,
      "grad_norm": 0.7176916003227234,
      "learning_rate": 1.3614542887398519e-05,
      "loss": 1.6251,
      "step": 1910
    },
    {
      "epoch": 0.998764549060407,
      "grad_norm": 0.6230166554450989,
      "learning_rate": 1.3579244617013767e-05,
      "loss": 1.613,
      "step": 1920
    },
    {
      "epoch": 1.003641329085116,
      "grad_norm": 0.9692516326904297,
      "learning_rate": 1.3543946346629016e-05,
      "loss": 1.7316,
      "step": 1930
    },
    {
      "epoch": 1.008843227778139,
      "grad_norm": 0.9005521535873413,
      "learning_rate": 1.3508648076244266e-05,
      "loss": 1.6661,
      "step": 1940
    },
    {
      "epoch": 1.014045126471162,
      "grad_norm": 0.7690843343734741,
      "learning_rate": 1.3473349805859515e-05,
      "loss": 1.7205,
      "step": 1950
    },
    {
      "epoch": 1.019247025164185,
      "grad_norm": 0.4889242947101593,
      "learning_rate": 1.3438051535474763e-05,
      "loss": 1.6259,
      "step": 1960
    },
    {
      "epoch": 1.0244489238572079,
      "grad_norm": 0.6998979449272156,
      "learning_rate": 1.340275326509001e-05,
      "loss": 1.5885,
      "step": 1970
    },
    {
      "epoch": 1.0296508225502308,
      "grad_norm": 0.6359609961509705,
      "learning_rate": 1.336745499470526e-05,
      "loss": 1.7072,
      "step": 1980
    },
    {
      "epoch": 1.034852721243254,
      "grad_norm": 0.6525626182556152,
      "learning_rate": 1.3332156724320508e-05,
      "loss": 1.6111,
      "step": 1990
    },
    {
      "epoch": 1.0400546199362768,
      "grad_norm": 0.8190814852714539,
      "learning_rate": 1.329685845393576e-05,
      "loss": 1.6543,
      "step": 2000
    },
    {
      "epoch": 1.0452565186292997,
      "grad_norm": 0.7023459076881409,
      "learning_rate": 1.3261560183551007e-05,
      "loss": 1.6513,
      "step": 2010
    },
    {
      "epoch": 1.0504584173223226,
      "grad_norm": 0.8594791889190674,
      "learning_rate": 1.3226261913166257e-05,
      "loss": 1.5879,
      "step": 2020
    },
    {
      "epoch": 1.0556603160153455,
      "grad_norm": 0.8558618426322937,
      "learning_rate": 1.3190963642781504e-05,
      "loss": 1.7025,
      "step": 2030
    },
    {
      "epoch": 1.0608622147083686,
      "grad_norm": 0.716847836971283,
      "learning_rate": 1.3155665372396754e-05,
      "loss": 1.7291,
      "step": 2040
    },
    {
      "epoch": 1.0660641134013915,
      "grad_norm": 0.6530740857124329,
      "learning_rate": 1.3120367102012002e-05,
      "loss": 1.6909,
      "step": 2050
    },
    {
      "epoch": 1.0712660120944144,
      "grad_norm": 0.9019004702568054,
      "learning_rate": 1.3085068831627253e-05,
      "loss": 1.5523,
      "step": 2060
    },
    {
      "epoch": 1.0764679107874375,
      "grad_norm": 0.6608284711837769,
      "learning_rate": 1.30497705612425e-05,
      "loss": 1.6547,
      "step": 2070
    },
    {
      "epoch": 1.0816698094804604,
      "grad_norm": 0.6751863956451416,
      "learning_rate": 1.3014472290857748e-05,
      "loss": 1.6508,
      "step": 2080
    },
    {
      "epoch": 1.0868717081734833,
      "grad_norm": 0.6431766748428345,
      "learning_rate": 1.2979174020472998e-05,
      "loss": 1.7074,
      "step": 2090
    },
    {
      "epoch": 1.0920736068665062,
      "grad_norm": 0.6163275241851807,
      "learning_rate": 1.2943875750088246e-05,
      "loss": 1.6621,
      "step": 2100
    },
    {
      "epoch": 1.0972755055595291,
      "grad_norm": 0.8314068913459778,
      "learning_rate": 1.2908577479703495e-05,
      "loss": 1.6929,
      "step": 2110
    },
    {
      "epoch": 1.1024774042525523,
      "grad_norm": 0.7244851589202881,
      "learning_rate": 1.2873279209318745e-05,
      "loss": 1.6542,
      "step": 2120
    },
    {
      "epoch": 1.1076793029455752,
      "grad_norm": 1.1062732934951782,
      "learning_rate": 1.2837980938933994e-05,
      "loss": 1.6238,
      "step": 2130
    },
    {
      "epoch": 1.112881201638598,
      "grad_norm": 0.6244587302207947,
      "learning_rate": 1.2802682668549242e-05,
      "loss": 1.5728,
      "step": 2140
    },
    {
      "epoch": 1.118083100331621,
      "grad_norm": 0.6778951287269592,
      "learning_rate": 1.276738439816449e-05,
      "loss": 1.5467,
      "step": 2150
    },
    {
      "epoch": 1.123284999024644,
      "grad_norm": 1.0783443450927734,
      "learning_rate": 1.273208612777974e-05,
      "loss": 1.7621,
      "step": 2160
    },
    {
      "epoch": 1.128486897717667,
      "grad_norm": 0.7632753849029541,
      "learning_rate": 1.2696787857394987e-05,
      "loss": 1.6966,
      "step": 2170
    },
    {
      "epoch": 1.1336887964106899,
      "grad_norm": 0.8939533233642578,
      "learning_rate": 1.2661489587010238e-05,
      "loss": 1.6232,
      "step": 2180
    },
    {
      "epoch": 1.1388906951037128,
      "grad_norm": 0.7190974950790405,
      "learning_rate": 1.2626191316625486e-05,
      "loss": 1.6317,
      "step": 2190
    },
    {
      "epoch": 1.144092593796736,
      "grad_norm": 0.8192511200904846,
      "learning_rate": 1.2590893046240736e-05,
      "loss": 1.6963,
      "step": 2200
    },
    {
      "epoch": 1.1492944924897588,
      "grad_norm": 0.6054002046585083,
      "learning_rate": 1.2555594775855983e-05,
      "loss": 1.6262,
      "step": 2210
    },
    {
      "epoch": 1.1544963911827817,
      "grad_norm": 0.5648412108421326,
      "learning_rate": 1.2520296505471233e-05,
      "loss": 1.7451,
      "step": 2220
    },
    {
      "epoch": 1.1596982898758046,
      "grad_norm": 0.6890102028846741,
      "learning_rate": 1.248499823508648e-05,
      "loss": 1.6399,
      "step": 2230
    },
    {
      "epoch": 1.1649001885688277,
      "grad_norm": 0.8320920467376709,
      "learning_rate": 1.2449699964701732e-05,
      "loss": 1.5476,
      "step": 2240
    },
    {
      "epoch": 1.1701020872618506,
      "grad_norm": 0.6614474654197693,
      "learning_rate": 1.241440169431698e-05,
      "loss": 1.7226,
      "step": 2250
    },
    {
      "epoch": 1.1753039859548735,
      "grad_norm": 0.754913866519928,
      "learning_rate": 1.2379103423932228e-05,
      "loss": 1.6668,
      "step": 2260
    },
    {
      "epoch": 1.1805058846478964,
      "grad_norm": 0.7107352614402771,
      "learning_rate": 1.2343805153547477e-05,
      "loss": 1.6626,
      "step": 2270
    },
    {
      "epoch": 1.1857077833409195,
      "grad_norm": 0.6119776368141174,
      "learning_rate": 1.2308506883162725e-05,
      "loss": 1.7539,
      "step": 2280
    },
    {
      "epoch": 1.1909096820339424,
      "grad_norm": 0.7755181193351746,
      "learning_rate": 1.2273208612777976e-05,
      "loss": 1.6787,
      "step": 2290
    },
    {
      "epoch": 1.1961115807269653,
      "grad_norm": 0.6875474452972412,
      "learning_rate": 1.2237910342393224e-05,
      "loss": 1.8894,
      "step": 2300
    },
    {
      "epoch": 1.2013134794199882,
      "grad_norm": 1.1209725141525269,
      "learning_rate": 1.2202612072008473e-05,
      "loss": 1.6921,
      "step": 2310
    },
    {
      "epoch": 1.2065153781130111,
      "grad_norm": 0.8368660807609558,
      "learning_rate": 1.2167313801623721e-05,
      "loss": 1.7709,
      "step": 2320
    },
    {
      "epoch": 1.2117172768060342,
      "grad_norm": 0.838603675365448,
      "learning_rate": 1.213201553123897e-05,
      "loss": 1.658,
      "step": 2330
    },
    {
      "epoch": 1.2169191754990571,
      "grad_norm": 0.8549337387084961,
      "learning_rate": 1.2096717260854218e-05,
      "loss": 1.7172,
      "step": 2340
    },
    {
      "epoch": 1.22212107419208,
      "grad_norm": 0.9860572814941406,
      "learning_rate": 1.206141899046947e-05,
      "loss": 1.6852,
      "step": 2350
    },
    {
      "epoch": 1.2273229728851032,
      "grad_norm": 0.9071571230888367,
      "learning_rate": 1.2026120720084717e-05,
      "loss": 1.5715,
      "step": 2360
    },
    {
      "epoch": 1.232524871578126,
      "grad_norm": 0.976172685623169,
      "learning_rate": 1.1990822449699965e-05,
      "loss": 1.5751,
      "step": 2370
    },
    {
      "epoch": 1.237726770271149,
      "grad_norm": NaN,
      "learning_rate": 1.1955524179315215e-05,
      "loss": 1.833,
      "step": 2380
    },
    {
      "epoch": 1.2429286689641719,
      "grad_norm": 0.7756818532943726,
      "learning_rate": 1.1923755735968938e-05,
      "loss": 1.5889,
      "step": 2390
    },
    {
      "epoch": 1.2481305676571948,
      "grad_norm": 0.9948564171791077,
      "learning_rate": 1.1888457465584186e-05,
      "loss": 1.7211,
      "step": 2400
    },
    {
      "epoch": 1.2533324663502179,
      "grad_norm": 0.8967714309692383,
      "learning_rate": 1.1853159195199435e-05,
      "loss": 1.6941,
      "step": 2410
    },
    {
      "epoch": 1.2585343650432408,
      "grad_norm": 1.1640264987945557,
      "learning_rate": 1.1817860924814687e-05,
      "loss": 1.6576,
      "step": 2420
    },
    {
      "epoch": 1.2637362637362637,
      "grad_norm": 0.7417382001876831,
      "learning_rate": 1.1782562654429934e-05,
      "loss": 1.6946,
      "step": 2430
    },
    {
      "epoch": 1.2689381624292868,
      "grad_norm": 0.6641841530799866,
      "learning_rate": 1.1747264384045182e-05,
      "loss": 1.7589,
      "step": 2440
    },
    {
      "epoch": 1.2741400611223097,
      "grad_norm": 0.8243926763534546,
      "learning_rate": 1.1711966113660432e-05,
      "loss": 1.6839,
      "step": 2450
    },
    {
      "epoch": 1.2793419598153326,
      "grad_norm": 0.780289351940155,
      "learning_rate": 1.167666784327568e-05,
      "loss": 1.6409,
      "step": 2460
    },
    {
      "epoch": 1.2845438585083555,
      "grad_norm": 0.8463918566703796,
      "learning_rate": 1.164136957289093e-05,
      "loss": 1.7341,
      "step": 2470
    },
    {
      "epoch": 1.2897457572013784,
      "grad_norm": 0.6855283975601196,
      "learning_rate": 1.1606071302506178e-05,
      "loss": 1.6378,
      "step": 2480
    },
    {
      "epoch": 1.2949476558944015,
      "grad_norm": 0.6606010794639587,
      "learning_rate": 1.1570773032121428e-05,
      "loss": 1.5794,
      "step": 2490
    },
    {
      "epoch": 1.3001495545874244,
      "grad_norm": 0.6431005597114563,
      "learning_rate": 1.1535474761736676e-05,
      "loss": 1.6239,
      "step": 2500
    },
    {
      "epoch": 1.3053514532804473,
      "grad_norm": 0.6791911721229553,
      "learning_rate": 1.1500176491351924e-05,
      "loss": 1.5741,
      "step": 2510
    },
    {
      "epoch": 1.3105533519734704,
      "grad_norm": 1.1952240467071533,
      "learning_rate": 1.1464878220967173e-05,
      "loss": 1.701,
      "step": 2520
    },
    {
      "epoch": 1.3157552506664933,
      "grad_norm": 0.7952952980995178,
      "learning_rate": 1.1429579950582424e-05,
      "loss": 1.7137,
      "step": 2530
    },
    {
      "epoch": 1.3209571493595162,
      "grad_norm": 0.834307849407196,
      "learning_rate": 1.1394281680197672e-05,
      "loss": 1.7005,
      "step": 2540
    },
    {
      "epoch": 1.3261590480525391,
      "grad_norm": 0.6651963591575623,
      "learning_rate": 1.135898340981292e-05,
      "loss": 1.5719,
      "step": 2550
    },
    {
      "epoch": 1.331360946745562,
      "grad_norm": 0.5293146967887878,
      "learning_rate": 1.132368513942817e-05,
      "loss": 1.5914,
      "step": 2560
    },
    {
      "epoch": 1.3365628454385852,
      "grad_norm": 0.9009467959403992,
      "learning_rate": 1.1288386869043417e-05,
      "loss": 1.6989,
      "step": 2570
    },
    {
      "epoch": 1.341764744131608,
      "grad_norm": 0.9592471122741699,
      "learning_rate": 1.1253088598658665e-05,
      "loss": 1.7185,
      "step": 2580
    },
    {
      "epoch": 1.346966642824631,
      "grad_norm": 0.7947309017181396,
      "learning_rate": 1.1217790328273916e-05,
      "loss": 1.7595,
      "step": 2590
    },
    {
      "epoch": 1.3521685415176539,
      "grad_norm": 0.8629213571548462,
      "learning_rate": 1.1182492057889166e-05,
      "loss": 1.68,
      "step": 2600
    },
    {
      "epoch": 1.3573704402106768,
      "grad_norm": 0.7763263583183289,
      "learning_rate": 1.1147193787504413e-05,
      "loss": 1.7645,
      "step": 2610
    },
    {
      "epoch": 1.3625723389036999,
      "grad_norm": 0.6008071899414062,
      "learning_rate": 1.1111895517119661e-05,
      "loss": 1.6482,
      "step": 2620
    },
    {
      "epoch": 1.3677742375967228,
      "grad_norm": 0.7267583012580872,
      "learning_rate": 1.107659724673491e-05,
      "loss": 1.572,
      "step": 2630
    },
    {
      "epoch": 1.3729761362897457,
      "grad_norm": 0.8280835151672363,
      "learning_rate": 1.1041298976350158e-05,
      "loss": 1.6463,
      "step": 2640
    },
    {
      "epoch": 1.3781780349827688,
      "grad_norm": 0.6731911301612854,
      "learning_rate": 1.100600070596541e-05,
      "loss": 1.5859,
      "step": 2650
    },
    {
      "epoch": 1.3833799336757917,
      "grad_norm": 0.8138006925582886,
      "learning_rate": 1.0970702435580657e-05,
      "loss": 1.6965,
      "step": 2660
    },
    {
      "epoch": 1.3885818323688146,
      "grad_norm": 0.769788384437561,
      "learning_rate": 1.0935404165195907e-05,
      "loss": 1.5633,
      "step": 2670
    },
    {
      "epoch": 1.3937837310618375,
      "grad_norm": 0.7058404088020325,
      "learning_rate": 1.0900105894811155e-05,
      "loss": 1.6869,
      "step": 2680
    },
    {
      "epoch": 1.3989856297548604,
      "grad_norm": 0.670869767665863,
      "learning_rate": 1.0864807624426403e-05,
      "loss": 1.7399,
      "step": 2690
    },
    {
      "epoch": 1.4041875284478835,
      "grad_norm": 0.6025049686431885,
      "learning_rate": 1.0829509354041652e-05,
      "loss": 1.7388,
      "step": 2700
    },
    {
      "epoch": 1.4093894271409064,
      "grad_norm": 0.7484608292579651,
      "learning_rate": 1.0794211083656903e-05,
      "loss": 1.6324,
      "step": 2710
    },
    {
      "epoch": 1.4145913258339293,
      "grad_norm": 0.6299939751625061,
      "learning_rate": 1.0758912813272151e-05,
      "loss": 1.5313,
      "step": 2720
    },
    {
      "epoch": 1.4197932245269524,
      "grad_norm": 0.8617337346076965,
      "learning_rate": 1.0723614542887399e-05,
      "loss": 1.6145,
      "step": 2730
    },
    {
      "epoch": 1.4249951232199753,
      "grad_norm": 1.0119847059249878,
      "learning_rate": 1.0688316272502648e-05,
      "loss": 1.7294,
      "step": 2740
    },
    {
      "epoch": 1.4301970219129982,
      "grad_norm": 0.621159553527832,
      "learning_rate": 1.0653018002117896e-05,
      "loss": 1.5964,
      "step": 2750
    },
    {
      "epoch": 1.4353989206060211,
      "grad_norm": 0.677708089351654,
      "learning_rate": 1.0617719731733146e-05,
      "loss": 1.589,
      "step": 2760
    },
    {
      "epoch": 1.440600819299044,
      "grad_norm": 0.7887158989906311,
      "learning_rate": 1.0582421461348395e-05,
      "loss": 1.6341,
      "step": 2770
    },
    {
      "epoch": 1.4458027179920672,
      "grad_norm": 0.8958141803741455,
      "learning_rate": 1.0547123190963645e-05,
      "loss": 1.6811,
      "step": 2780
    },
    {
      "epoch": 1.45100461668509,
      "grad_norm": 0.8076881170272827,
      "learning_rate": 1.0511824920578892e-05,
      "loss": 1.7109,
      "step": 2790
    },
    {
      "epoch": 1.456206515378113,
      "grad_norm": 0.7605285048484802,
      "learning_rate": 1.047652665019414e-05,
      "loss": 1.7605,
      "step": 2800
    },
    {
      "epoch": 1.461408414071136,
      "grad_norm": 0.7581567764282227,
      "learning_rate": 1.044122837980939e-05,
      "loss": 1.615,
      "step": 2810
    },
    {
      "epoch": 1.466610312764159,
      "grad_norm": 0.6407274007797241,
      "learning_rate": 1.0405930109424641e-05,
      "loss": 1.585,
      "step": 2820
    },
    {
      "epoch": 1.4718122114571819,
      "grad_norm": 0.7314239144325256,
      "learning_rate": 1.0370631839039889e-05,
      "loss": 1.6478,
      "step": 2830
    },
    {
      "epoch": 1.4770141101502048,
      "grad_norm": 0.6579530239105225,
      "learning_rate": 1.0335333568655137e-05,
      "loss": 1.6116,
      "step": 2840
    },
    {
      "epoch": 1.4822160088432277,
      "grad_norm": 0.8784440159797668,
      "learning_rate": 1.0300035298270386e-05,
      "loss": 1.748,
      "step": 2850
    },
    {
      "epoch": 1.4874179075362508,
      "grad_norm": 1.0009437799453735,
      "learning_rate": 1.0264737027885634e-05,
      "loss": 1.6519,
      "step": 2860
    },
    {
      "epoch": 1.4926198062292737,
      "grad_norm": 0.7221645712852478,
      "learning_rate": 1.0229438757500882e-05,
      "loss": 1.6716,
      "step": 2870
    },
    {
      "epoch": 1.4978217049222966,
      "grad_norm": 0.6138758659362793,
      "learning_rate": 1.0194140487116133e-05,
      "loss": 1.6526,
      "step": 2880
    },
    {
      "epoch": 1.5030236036153197,
      "grad_norm": 0.9557003378868103,
      "learning_rate": 1.0158842216731382e-05,
      "loss": 1.6973,
      "step": 2890
    },
    {
      "epoch": 1.5082255023083424,
      "grad_norm": 0.8203555941581726,
      "learning_rate": 1.012354394634663e-05,
      "loss": 1.7418,
      "step": 2900
    },
    {
      "epoch": 1.5134274010013655,
      "grad_norm": 0.7753478288650513,
      "learning_rate": 1.0088245675961878e-05,
      "loss": 1.5455,
      "step": 2910
    },
    {
      "epoch": 1.5186292996943884,
      "grad_norm": 0.6749258637428284,
      "learning_rate": 1.0052947405577127e-05,
      "loss": 1.681,
      "step": 2920
    },
    {
      "epoch": 1.5238311983874113,
      "grad_norm": 1.1105011701583862,
      "learning_rate": 1.0017649135192375e-05,
      "loss": 1.7059,
      "step": 2930
    },
    {
      "epoch": 1.5290330970804344,
      "grad_norm": 0.7440073490142822,
      "learning_rate": 9.982350864807625e-06,
      "loss": 1.5639,
      "step": 2940
    },
    {
      "epoch": 1.5342349957734573,
      "grad_norm": 0.7042028307914734,
      "learning_rate": 9.947052594422874e-06,
      "loss": 1.6227,
      "step": 2950
    },
    {
      "epoch": 1.5394368944664802,
      "grad_norm": 0.7476150393486023,
      "learning_rate": 9.911754324038124e-06,
      "loss": 1.6055,
      "step": 2960
    },
    {
      "epoch": 1.5446387931595034,
      "grad_norm": 0.8530107140541077,
      "learning_rate": 9.876456053653372e-06,
      "loss": 1.6296,
      "step": 2970
    },
    {
      "epoch": 1.549840691852526,
      "grad_norm": 0.8150180578231812,
      "learning_rate": 9.841157783268621e-06,
      "loss": 1.7619,
      "step": 2980
    },
    {
      "epoch": 1.5550425905455492,
      "grad_norm": 0.7638901472091675,
      "learning_rate": 9.805859512883869e-06,
      "loss": 1.7055,
      "step": 2990
    },
    {
      "epoch": 1.560244489238572,
      "grad_norm": 0.7275540232658386,
      "learning_rate": 9.770561242499118e-06,
      "loss": 1.7516,
      "step": 3000
    },
    {
      "epoch": 1.565446387931595,
      "grad_norm": 1.0600597858428955,
      "learning_rate": 9.735262972114368e-06,
      "loss": 1.6143,
      "step": 3010
    },
    {
      "epoch": 1.570648286624618,
      "grad_norm": 0.8551778197288513,
      "learning_rate": 9.699964701729616e-06,
      "loss": 1.7179,
      "step": 3020
    },
    {
      "epoch": 1.575850185317641,
      "grad_norm": 0.726256251335144,
      "learning_rate": 9.664666431344865e-06,
      "loss": 1.6335,
      "step": 3030
    },
    {
      "epoch": 1.5810520840106639,
      "grad_norm": 0.8819499015808105,
      "learning_rate": 9.629368160960115e-06,
      "loss": 1.7758,
      "step": 3040
    },
    {
      "epoch": 1.586253982703687,
      "grad_norm": 0.8580489158630371,
      "learning_rate": 9.594069890575362e-06,
      "loss": 1.7876,
      "step": 3050
    },
    {
      "epoch": 1.5914558813967097,
      "grad_norm": 0.6783758401870728,
      "learning_rate": 9.558771620190612e-06,
      "loss": 1.5628,
      "step": 3060
    },
    {
      "epoch": 1.5966577800897328,
      "grad_norm": 0.7895386815071106,
      "learning_rate": 9.523473349805861e-06,
      "loss": 1.6273,
      "step": 3070
    },
    {
      "epoch": 1.6018596787827557,
      "grad_norm": 0.69542396068573,
      "learning_rate": 9.48817507942111e-06,
      "loss": 1.6141,
      "step": 3080
    },
    {
      "epoch": 1.6070615774757786,
      "grad_norm": 0.8122459053993225,
      "learning_rate": 9.452876809036357e-06,
      "loss": 1.6386,
      "step": 3090
    },
    {
      "epoch": 1.6122634761688017,
      "grad_norm": 0.6454382538795471,
      "learning_rate": 9.417578538651606e-06,
      "loss": 1.6399,
      "step": 3100
    },
    {
      "epoch": 1.6174653748618244,
      "grad_norm": 0.8577333688735962,
      "learning_rate": 9.382280268266856e-06,
      "loss": 1.7264,
      "step": 3110
    },
    {
      "epoch": 1.6226672735548475,
      "grad_norm": 1.0108755826950073,
      "learning_rate": 9.346981997882104e-06,
      "loss": 1.7,
      "step": 3120
    },
    {
      "epoch": 1.6278691722478704,
      "grad_norm": 1.1424752473831177,
      "learning_rate": 9.311683727497353e-06,
      "loss": 1.6035,
      "step": 3130
    },
    {
      "epoch": 1.6330710709408933,
      "grad_norm": 0.6684921979904175,
      "learning_rate": 9.276385457112603e-06,
      "loss": 1.5758,
      "step": 3140
    },
    {
      "epoch": 1.6382729696339164,
      "grad_norm": 0.8078777194023132,
      "learning_rate": 9.24108718672785e-06,
      "loss": 1.6482,
      "step": 3150
    },
    {
      "epoch": 1.6434748683269393,
      "grad_norm": 0.8203304409980774,
      "learning_rate": 9.2057889163431e-06,
      "loss": 1.6407,
      "step": 3160
    },
    {
      "epoch": 1.6486767670199622,
      "grad_norm": 0.8002521395683289,
      "learning_rate": 9.170490645958348e-06,
      "loss": 1.674,
      "step": 3170
    },
    {
      "epoch": 1.6538786657129854,
      "grad_norm": 0.8156700134277344,
      "learning_rate": 9.135192375573597e-06,
      "loss": 1.4657,
      "step": 3180
    },
    {
      "epoch": 1.659080564406008,
      "grad_norm": 0.791359543800354,
      "learning_rate": 9.099894105188847e-06,
      "loss": 1.7522,
      "step": 3190
    },
    {
      "epoch": 1.6642824630990312,
      "grad_norm": 0.8249953985214233,
      "learning_rate": 9.064595834804095e-06,
      "loss": 1.6377,
      "step": 3200
    },
    {
      "epoch": 1.669484361792054,
      "grad_norm": 0.8398008346557617,
      "learning_rate": 9.029297564419344e-06,
      "loss": 1.6175,
      "step": 3210
    },
    {
      "epoch": 1.674686260485077,
      "grad_norm": 0.7268000245094299,
      "learning_rate": 8.993999294034594e-06,
      "loss": 1.703,
      "step": 3220
    },
    {
      "epoch": 1.6798881591781,
      "grad_norm": 0.7993088960647583,
      "learning_rate": 8.958701023649841e-06,
      "loss": 1.6609,
      "step": 3230
    },
    {
      "epoch": 1.685090057871123,
      "grad_norm": 0.7858840227127075,
      "learning_rate": 8.923402753265091e-06,
      "loss": 1.5823,
      "step": 3240
    },
    {
      "epoch": 1.6902919565641459,
      "grad_norm": 0.8132704496383667,
      "learning_rate": 8.88810448288034e-06,
      "loss": 1.5798,
      "step": 3250
    },
    {
      "epoch": 1.695493855257169,
      "grad_norm": 0.8096762299537659,
      "learning_rate": 8.852806212495588e-06,
      "loss": 1.6977,
      "step": 3260
    },
    {
      "epoch": 1.7006957539501917,
      "grad_norm": 0.7088226675987244,
      "learning_rate": 8.817507942110838e-06,
      "loss": 1.7135,
      "step": 3270
    },
    {
      "epoch": 1.7058976526432148,
      "grad_norm": 0.7772283554077148,
      "learning_rate": 8.782209671726086e-06,
      "loss": 1.7816,
      "step": 3280
    },
    {
      "epoch": 1.7110995513362377,
      "grad_norm": 0.8526436686515808,
      "learning_rate": 8.746911401341335e-06,
      "loss": 1.7378,
      "step": 3290
    },
    {
      "epoch": 1.7163014500292606,
      "grad_norm": 0.7654470205307007,
      "learning_rate": 8.711613130956585e-06,
      "loss": 1.6486,
      "step": 3300
    },
    {
      "epoch": 1.7215033487222837,
      "grad_norm": 0.75885409116745,
      "learning_rate": 8.676314860571832e-06,
      "loss": 1.6785,
      "step": 3310
    },
    {
      "epoch": 1.7267052474153066,
      "grad_norm": 0.925317645072937,
      "learning_rate": 8.641016590187082e-06,
      "loss": 1.6928,
      "step": 3320
    },
    {
      "epoch": 1.7319071461083295,
      "grad_norm": 0.7437067627906799,
      "learning_rate": 8.605718319802331e-06,
      "loss": 1.6977,
      "step": 3330
    },
    {
      "epoch": 1.7371090448013526,
      "grad_norm": 0.9075771570205688,
      "learning_rate": 8.570420049417579e-06,
      "loss": 1.6293,
      "step": 3340
    },
    {
      "epoch": 1.7423109434943753,
      "grad_norm": 1.0349351167678833,
      "learning_rate": 8.535121779032829e-06,
      "loss": 1.717,
      "step": 3350
    },
    {
      "epoch": 1.7475128421873984,
      "grad_norm": 0.6655510067939758,
      "learning_rate": 8.499823508648078e-06,
      "loss": 1.6879,
      "step": 3360
    },
    {
      "epoch": 1.7527147408804213,
      "grad_norm": 0.8869290351867676,
      "learning_rate": 8.464525238263326e-06,
      "loss": 1.6033,
      "step": 3370
    },
    {
      "epoch": 1.7579166395734442,
      "grad_norm": 0.7516579031944275,
      "learning_rate": 8.429226967878574e-06,
      "loss": 1.5349,
      "step": 3380
    },
    {
      "epoch": 1.7631185382664674,
      "grad_norm": 0.7319429516792297,
      "learning_rate": 8.393928697493823e-06,
      "loss": 1.6815,
      "step": 3390
    },
    {
      "epoch": 1.7683204369594903,
      "grad_norm": 0.9194182753562927,
      "learning_rate": 8.358630427109073e-06,
      "loss": 1.7458,
      "step": 3400
    },
    {
      "epoch": 1.7735223356525132,
      "grad_norm": 0.6545854806900024,
      "learning_rate": 8.32333215672432e-06,
      "loss": 1.6907,
      "step": 3410
    },
    {
      "epoch": 1.7787242343455363,
      "grad_norm": 0.7708125710487366,
      "learning_rate": 8.28803388633957e-06,
      "loss": 1.6974,
      "step": 3420
    },
    {
      "epoch": 1.783926133038559,
      "grad_norm": 0.8113338351249695,
      "learning_rate": 8.25273561595482e-06,
      "loss": 1.7477,
      "step": 3430
    },
    {
      "epoch": 1.789128031731582,
      "grad_norm": 0.6615857481956482,
      "learning_rate": 8.217437345570067e-06,
      "loss": 1.7341,
      "step": 3440
    },
    {
      "epoch": 1.794329930424605,
      "grad_norm": 1.0025984048843384,
      "learning_rate": 8.182139075185317e-06,
      "loss": 1.6225,
      "step": 3450
    },
    {
      "epoch": 1.7995318291176279,
      "grad_norm": 1.1698979139328003,
      "learning_rate": 8.146840804800565e-06,
      "loss": 1.7041,
      "step": 3460
    },
    {
      "epoch": 1.804733727810651,
      "grad_norm": 0.7873163223266602,
      "learning_rate": 8.111542534415814e-06,
      "loss": 1.6926,
      "step": 3470
    },
    {
      "epoch": 1.8099356265036737,
      "grad_norm": 0.9125732183456421,
      "learning_rate": 8.076244264031064e-06,
      "loss": 1.8465,
      "step": 3480
    },
    {
      "epoch": 1.8151375251966968,
      "grad_norm": 0.7614739537239075,
      "learning_rate": 8.040945993646311e-06,
      "loss": 1.6858,
      "step": 3490
    },
    {
      "epoch": 1.8203394238897197,
      "grad_norm": 0.761086642742157,
      "learning_rate": 8.005647723261561e-06,
      "loss": 1.6755,
      "step": 3500
    },
    {
      "epoch": 1.8255413225827426,
      "grad_norm": 0.7935827374458313,
      "learning_rate": 7.97034945287681e-06,
      "loss": 1.7224,
      "step": 3510
    },
    {
      "epoch": 1.8307432212757657,
      "grad_norm": 0.7913548350334167,
      "learning_rate": 7.935051182492058e-06,
      "loss": 1.615,
      "step": 3520
    },
    {
      "epoch": 1.8359451199687886,
      "grad_norm": 1.0430970191955566,
      "learning_rate": 7.899752912107308e-06,
      "loss": 1.6519,
      "step": 3530
    },
    {
      "epoch": 1.8411470186618115,
      "grad_norm": 0.8986480236053467,
      "learning_rate": 7.864454641722557e-06,
      "loss": 1.6742,
      "step": 3540
    },
    {
      "epoch": 1.8463489173548346,
      "grad_norm": 0.761602520942688,
      "learning_rate": 7.829156371337805e-06,
      "loss": 1.6294,
      "step": 3550
    },
    {
      "epoch": 1.8515508160478573,
      "grad_norm": 0.8252968192100525,
      "learning_rate": 7.793858100953053e-06,
      "loss": 1.7016,
      "step": 3560
    },
    {
      "epoch": 1.8567527147408804,
      "grad_norm": 0.6221346855163574,
      "learning_rate": 7.758559830568302e-06,
      "loss": 1.6996,
      "step": 3570
    },
    {
      "epoch": 1.8619546134339033,
      "grad_norm": 0.6797427535057068,
      "learning_rate": 7.723261560183552e-06,
      "loss": 1.6453,
      "step": 3580
    },
    {
      "epoch": 1.8671565121269262,
      "grad_norm": 0.6746202111244202,
      "learning_rate": 7.687963289798801e-06,
      "loss": 1.6408,
      "step": 3590
    },
    {
      "epoch": 1.8723584108199494,
      "grad_norm": 0.8751141428947449,
      "learning_rate": 7.652665019414049e-06,
      "loss": 1.706,
      "step": 3600
    },
    {
      "epoch": 1.8775603095129723,
      "grad_norm": 0.9894208312034607,
      "learning_rate": 7.617366749029298e-06,
      "loss": 1.6287,
      "step": 3610
    },
    {
      "epoch": 1.8827622082059952,
      "grad_norm": 0.7049940824508667,
      "learning_rate": 7.582068478644547e-06,
      "loss": 1.8354,
      "step": 3620
    },
    {
      "epoch": 1.8879641068990183,
      "grad_norm": 0.6069444417953491,
      "learning_rate": 7.546770208259796e-06,
      "loss": 1.6579,
      "step": 3630
    },
    {
      "epoch": 1.893166005592041,
      "grad_norm": 0.775571882724762,
      "learning_rate": 7.5114719378750445e-06,
      "loss": 1.593,
      "step": 3640
    },
    {
      "epoch": 1.898367904285064,
      "grad_norm": 0.6337679624557495,
      "learning_rate": 7.476173667490294e-06,
      "loss": 1.7317,
      "step": 3650
    },
    {
      "epoch": 1.903569802978087,
      "grad_norm": 1.34699285030365,
      "learning_rate": 7.440875397105543e-06,
      "loss": 1.5602,
      "step": 3660
    },
    {
      "epoch": 1.9087717016711099,
      "grad_norm": 0.9099279642105103,
      "learning_rate": 7.405577126720791e-06,
      "loss": 1.7475,
      "step": 3670
    },
    {
      "epoch": 1.913973600364133,
      "grad_norm": 0.893364667892456,
      "learning_rate": 7.370278856336041e-06,
      "loss": 1.6891,
      "step": 3680
    },
    {
      "epoch": 1.919175499057156,
      "grad_norm": 0.8036352396011353,
      "learning_rate": 7.334980585951289e-06,
      "loss": 1.6207,
      "step": 3690
    },
    {
      "epoch": 1.9243773977501788,
      "grad_norm": 0.7338208556175232,
      "learning_rate": 7.299682315566537e-06,
      "loss": 1.6746,
      "step": 3700
    },
    {
      "epoch": 1.929579296443202,
      "grad_norm": 0.6373203992843628,
      "learning_rate": 7.264384045181787e-06,
      "loss": 1.6405,
      "step": 3710
    },
    {
      "epoch": 1.9347811951362246,
      "grad_norm": 0.849659264087677,
      "learning_rate": 7.229085774797035e-06,
      "loss": 1.62,
      "step": 3720
    },
    {
      "epoch": 1.9399830938292477,
      "grad_norm": 0.5574666857719421,
      "learning_rate": 7.193787504412284e-06,
      "loss": 1.6875,
      "step": 3730
    },
    {
      "epoch": 1.9451849925222706,
      "grad_norm": 0.6047303080558777,
      "learning_rate": 7.1584892340275335e-06,
      "loss": 1.703,
      "step": 3740
    },
    {
      "epoch": 1.9503868912152935,
      "grad_norm": 0.7952791452407837,
      "learning_rate": 7.123190963642782e-06,
      "loss": 1.6183,
      "step": 3750
    },
    {
      "epoch": 1.9555887899083166,
      "grad_norm": 0.7513692378997803,
      "learning_rate": 7.087892693258031e-06,
      "loss": 1.7562,
      "step": 3760
    },
    {
      "epoch": 1.9607906886013395,
      "grad_norm": 0.5750228762626648,
      "learning_rate": 7.05259442287328e-06,
      "loss": 1.673,
      "step": 3770
    },
    {
      "epoch": 1.9659925872943624,
      "grad_norm": 0.6642153859138489,
      "learning_rate": 7.017296152488529e-06,
      "loss": 1.6575,
      "step": 3780
    },
    {
      "epoch": 1.9711944859873856,
      "grad_norm": 1.2758948802947998,
      "learning_rate": 6.981997882103777e-06,
      "loss": 1.6552,
      "step": 3790
    },
    {
      "epoch": 1.9763963846804082,
      "grad_norm": 0.7224435210227966,
      "learning_rate": 6.946699611719026e-06,
      "loss": 1.6223,
      "step": 3800
    },
    {
      "epoch": 1.9815982833734314,
      "grad_norm": 0.8622966408729553,
      "learning_rate": 6.911401341334275e-06,
      "loss": 1.6749,
      "step": 3810
    },
    {
      "epoch": 1.9868001820664543,
      "grad_norm": 0.7340735793113708,
      "learning_rate": 6.8761030709495235e-06,
      "loss": 1.6223,
      "step": 3820
    },
    {
      "epoch": 1.9920020807594772,
      "grad_norm": 0.6182805895805359,
      "learning_rate": 6.840804800564773e-06,
      "loss": 1.6252,
      "step": 3830
    },
    {
      "epoch": 1.9972039794525003,
      "grad_norm": 0.7972228527069092,
      "learning_rate": 6.805506530180022e-06,
      "loss": 1.6133,
      "step": 3840
    },
    {
      "epoch": 2.002080759477209,
      "grad_norm": 0.6158164739608765,
      "learning_rate": 6.77020825979527e-06,
      "loss": 1.6215,
      "step": 3850
    },
    {
      "epoch": 2.007282658170232,
      "grad_norm": 0.6833735704421997,
      "learning_rate": 6.73490998941052e-06,
      "loss": 1.6602,
      "step": 3860
    },
    {
      "epoch": 2.0124845568632552,
      "grad_norm": 0.7976641654968262,
      "learning_rate": 6.6996117190257685e-06,
      "loss": 1.6602,
      "step": 3870
    },
    {
      "epoch": 2.017686455556278,
      "grad_norm": 0.8679509162902832,
      "learning_rate": 6.664313448641016e-06,
      "loss": 1.6734,
      "step": 3880
    },
    {
      "epoch": 2.022888354249301,
      "grad_norm": 0.795028805732727,
      "learning_rate": 6.629015178256266e-06,
      "loss": 1.642,
      "step": 3890
    },
    {
      "epoch": 2.028090252942324,
      "grad_norm": 0.6494647264480591,
      "learning_rate": 6.593716907871514e-06,
      "loss": 1.6121,
      "step": 3900
    },
    {
      "epoch": 2.033292151635347,
      "grad_norm": 0.6786236763000488,
      "learning_rate": 6.558418637486764e-06,
      "loss": 1.5966,
      "step": 3910
    },
    {
      "epoch": 2.03849405032837,
      "grad_norm": 0.9225782155990601,
      "learning_rate": 6.5231203671020126e-06,
      "loss": 1.6625,
      "step": 3920
    },
    {
      "epoch": 2.0436959490213926,
      "grad_norm": 0.7248165607452393,
      "learning_rate": 6.487822096717261e-06,
      "loss": 1.6389,
      "step": 3930
    },
    {
      "epoch": 2.0488978477144157,
      "grad_norm": 0.7577533721923828,
      "learning_rate": 6.452523826332511e-06,
      "loss": 1.5759,
      "step": 3940
    },
    {
      "epoch": 2.054099746407439,
      "grad_norm": 0.6959691047668457,
      "learning_rate": 6.417225555947759e-06,
      "loss": 1.6332,
      "step": 3950
    },
    {
      "epoch": 2.0593016451004615,
      "grad_norm": 0.667543888092041,
      "learning_rate": 6.381927285563008e-06,
      "loss": 1.5914,
      "step": 3960
    },
    {
      "epoch": 2.0645035437934847,
      "grad_norm": 0.7060849666595459,
      "learning_rate": 6.3466290151782575e-06,
      "loss": 1.6358,
      "step": 3970
    },
    {
      "epoch": 2.069705442486508,
      "grad_norm": 0.5903549790382385,
      "learning_rate": 6.311330744793505e-06,
      "loss": 1.5871,
      "step": 3980
    },
    {
      "epoch": 2.0749073411795305,
      "grad_norm": 0.8090432286262512,
      "learning_rate": 6.276032474408754e-06,
      "loss": 1.5834,
      "step": 3990
    },
    {
      "epoch": 2.0801092398725536,
      "grad_norm": 0.6388727426528931,
      "learning_rate": 6.2407342040240034e-06,
      "loss": 1.6873,
      "step": 4000
    },
    {
      "epoch": 2.0853111385655763,
      "grad_norm": 0.8344226479530334,
      "learning_rate": 6.205435933639252e-06,
      "loss": 1.6996,
      "step": 4010
    },
    {
      "epoch": 2.0905130372585994,
      "grad_norm": 0.7633014917373657,
      "learning_rate": 6.170137663254501e-06,
      "loss": 1.8191,
      "step": 4020
    },
    {
      "epoch": 2.0957149359516225,
      "grad_norm": 0.801115095615387,
      "learning_rate": 6.13483939286975e-06,
      "loss": 1.6579,
      "step": 4030
    },
    {
      "epoch": 2.100916834644645,
      "grad_norm": 0.7594625949859619,
      "learning_rate": 6.099541122484999e-06,
      "loss": 1.6545,
      "step": 4040
    },
    {
      "epoch": 2.1061187333376683,
      "grad_norm": 0.7016628384590149,
      "learning_rate": 6.0642428521002475e-06,
      "loss": 1.7638,
      "step": 4050
    },
    {
      "epoch": 2.111320632030691,
      "grad_norm": 0.7972268462181091,
      "learning_rate": 6.028944581715497e-06,
      "loss": 1.6612,
      "step": 4060
    },
    {
      "epoch": 2.116522530723714,
      "grad_norm": 0.9690752625465393,
      "learning_rate": 5.993646311330746e-06,
      "loss": 1.6064,
      "step": 4070
    },
    {
      "epoch": 2.1217244294167372,
      "grad_norm": 1.005311131477356,
      "learning_rate": 5.9583480409459935e-06,
      "loss": 1.6025,
      "step": 4080
    },
    {
      "epoch": 2.12692632810976,
      "grad_norm": 0.7435919642448425,
      "learning_rate": 5.923049770561243e-06,
      "loss": 1.6095,
      "step": 4090
    },
    {
      "epoch": 2.132128226802783,
      "grad_norm": 0.8716053366661072,
      "learning_rate": 5.887751500176492e-06,
      "loss": 1.7573,
      "step": 4100
    },
    {
      "epoch": 2.137330125495806,
      "grad_norm": 0.6354235410690308,
      "learning_rate": 5.85245322979174e-06,
      "loss": 1.5616,
      "step": 4110
    },
    {
      "epoch": 2.142532024188829,
      "grad_norm": 0.7883342504501343,
      "learning_rate": 5.81715495940699e-06,
      "loss": 1.7014,
      "step": 4120
    },
    {
      "epoch": 2.147733922881852,
      "grad_norm": 0.6911888718605042,
      "learning_rate": 5.781856689022238e-06,
      "loss": 1.6569,
      "step": 4130
    },
    {
      "epoch": 2.152935821574875,
      "grad_norm": 0.7128761410713196,
      "learning_rate": 5.746558418637487e-06,
      "loss": 1.6482,
      "step": 4140
    },
    {
      "epoch": 2.1581377202678977,
      "grad_norm": 0.752350389957428,
      "learning_rate": 5.7112601482527365e-06,
      "loss": 1.6686,
      "step": 4150
    },
    {
      "epoch": 2.163339618960921,
      "grad_norm": 0.9178109765052795,
      "learning_rate": 5.675961877867985e-06,
      "loss": 1.7718,
      "step": 4160
    },
    {
      "epoch": 2.1685415176539435,
      "grad_norm": 0.7849741578102112,
      "learning_rate": 5.640663607483233e-06,
      "loss": 1.7164,
      "step": 4170
    },
    {
      "epoch": 2.1737434163469667,
      "grad_norm": 0.5612748265266418,
      "learning_rate": 5.6053653370984825e-06,
      "loss": 1.6111,
      "step": 4180
    },
    {
      "epoch": 2.17894531503999,
      "grad_norm": 0.9159628748893738,
      "learning_rate": 5.570067066713731e-06,
      "loss": 1.6267,
      "step": 4190
    },
    {
      "epoch": 2.1841472137330125,
      "grad_norm": 0.7852245569229126,
      "learning_rate": 5.53476879632898e-06,
      "loss": 1.6817,
      "step": 4200
    },
    {
      "epoch": 2.1893491124260356,
      "grad_norm": 0.8838732242584229,
      "learning_rate": 5.499470525944229e-06,
      "loss": 1.6174,
      "step": 4210
    },
    {
      "epoch": 2.1945510111190583,
      "grad_norm": 0.7140714526176453,
      "learning_rate": 5.464172255559478e-06,
      "loss": 1.6597,
      "step": 4220
    },
    {
      "epoch": 2.1997529098120814,
      "grad_norm": 0.7193710207939148,
      "learning_rate": 5.4288739851747274e-06,
      "loss": 1.5528,
      "step": 4230
    },
    {
      "epoch": 2.2049548085051045,
      "grad_norm": 0.7803349494934082,
      "learning_rate": 5.393575714789976e-06,
      "loss": 1.6852,
      "step": 4240
    },
    {
      "epoch": 2.210156707198127,
      "grad_norm": 0.6598735451698303,
      "learning_rate": 5.358277444405225e-06,
      "loss": 1.6832,
      "step": 4250
    },
    {
      "epoch": 2.2153586058911503,
      "grad_norm": 0.8718441724777222,
      "learning_rate": 5.322979174020474e-06,
      "loss": 1.5649,
      "step": 4260
    },
    {
      "epoch": 2.2205605045841734,
      "grad_norm": 0.7970663905143738,
      "learning_rate": 5.287680903635722e-06,
      "loss": 1.6324,
      "step": 4270
    },
    {
      "epoch": 2.225762403277196,
      "grad_norm": 0.6273996829986572,
      "learning_rate": 5.252382633250971e-06,
      "loss": 1.689,
      "step": 4280
    },
    {
      "epoch": 2.230964301970219,
      "grad_norm": 0.8145580887794495,
      "learning_rate": 5.21708436286622e-06,
      "loss": 1.7139,
      "step": 4290
    },
    {
      "epoch": 2.236166200663242,
      "grad_norm": 0.7347031235694885,
      "learning_rate": 5.181786092481469e-06,
      "loss": 1.6989,
      "step": 4300
    },
    {
      "epoch": 2.241368099356265,
      "grad_norm": 0.6016470193862915,
      "learning_rate": 5.1464878220967175e-06,
      "loss": 1.7251,
      "step": 4310
    },
    {
      "epoch": 2.246569998049288,
      "grad_norm": 0.9703313708305359,
      "learning_rate": 5.111189551711967e-06,
      "loss": 1.6547,
      "step": 4320
    },
    {
      "epoch": 2.251771896742311,
      "grad_norm": 0.9860453009605408,
      "learning_rate": 5.075891281327216e-06,
      "loss": 1.6161,
      "step": 4330
    },
    {
      "epoch": 2.256973795435334,
      "grad_norm": 1.0358800888061523,
      "learning_rate": 5.040593010942464e-06,
      "loss": 1.671,
      "step": 4340
    },
    {
      "epoch": 2.2621756941283566,
      "grad_norm": 0.6865041255950928,
      "learning_rate": 5.005294740557714e-06,
      "loss": 1.6698,
      "step": 4350
    },
    {
      "epoch": 2.2673775928213797,
      "grad_norm": 0.6362320184707642,
      "learning_rate": 4.9699964701729615e-06,
      "loss": 1.6346,
      "step": 4360
    },
    {
      "epoch": 2.272579491514403,
      "grad_norm": 0.695785403251648,
      "learning_rate": 4.934698199788211e-06,
      "loss": 1.8058,
      "step": 4370
    },
    {
      "epoch": 2.2777813902074255,
      "grad_norm": 0.8569940328598022,
      "learning_rate": 4.89939992940346e-06,
      "loss": 1.5853,
      "step": 4380
    },
    {
      "epoch": 2.2829832889004487,
      "grad_norm": 0.598229169845581,
      "learning_rate": 4.864101659018708e-06,
      "loss": 1.5859,
      "step": 4390
    },
    {
      "epoch": 2.288185187593472,
      "grad_norm": 0.6632369160652161,
      "learning_rate": 4.828803388633958e-06,
      "loss": 1.6172,
      "step": 4400
    },
    {
      "epoch": 2.2933870862864945,
      "grad_norm": 0.6221048831939697,
      "learning_rate": 4.793505118249206e-06,
      "loss": 1.6893,
      "step": 4410
    },
    {
      "epoch": 2.2985889849795176,
      "grad_norm": 0.964477002620697,
      "learning_rate": 4.758206847864455e-06,
      "loss": 1.6729,
      "step": 4420
    },
    {
      "epoch": 2.3037908836725407,
      "grad_norm": 0.7602934241294861,
      "learning_rate": 4.722908577479704e-06,
      "loss": 1.6622,
      "step": 4430
    },
    {
      "epoch": 2.3089927823655634,
      "grad_norm": 0.7573510408401489,
      "learning_rate": 4.6876103070949524e-06,
      "loss": 1.7536,
      "step": 4440
    },
    {
      "epoch": 2.3141946810585865,
      "grad_norm": 0.6755639910697937,
      "learning_rate": 4.652312036710201e-06,
      "loss": 1.5982,
      "step": 4450
    },
    {
      "epoch": 2.319396579751609,
      "grad_norm": 0.8303586840629578,
      "learning_rate": 4.6170137663254506e-06,
      "loss": 1.6006,
      "step": 4460
    },
    {
      "epoch": 2.3245984784446323,
      "grad_norm": 0.7418046593666077,
      "learning_rate": 4.581715495940699e-06,
      "loss": 1.6756,
      "step": 4470
    },
    {
      "epoch": 2.3298003771376554,
      "grad_norm": 0.6977664828300476,
      "learning_rate": 4.546417225555948e-06,
      "loss": 1.5918,
      "step": 4480
    },
    {
      "epoch": 2.335002275830678,
      "grad_norm": 0.8271996974945068,
      "learning_rate": 4.511118955171197e-06,
      "loss": 1.691,
      "step": 4490
    },
    {
      "epoch": 2.340204174523701,
      "grad_norm": 0.8679981231689453,
      "learning_rate": 4.475820684786446e-06,
      "loss": 1.6519,
      "step": 4500
    },
    {
      "epoch": 2.345406073216724,
      "grad_norm": 0.7892820835113525,
      "learning_rate": 4.440522414401695e-06,
      "loss": 1.5716,
      "step": 4510
    },
    {
      "epoch": 2.350607971909747,
      "grad_norm": 0.6700614094734192,
      "learning_rate": 4.405224144016943e-06,
      "loss": 1.7575,
      "step": 4520
    },
    {
      "epoch": 2.35580987060277,
      "grad_norm": 0.8891021609306335,
      "learning_rate": 4.369925873632193e-06,
      "loss": 1.5734,
      "step": 4530
    },
    {
      "epoch": 2.361011769295793,
      "grad_norm": 0.817649781703949,
      "learning_rate": 4.3346276032474414e-06,
      "loss": 1.6097,
      "step": 4540
    },
    {
      "epoch": 2.366213667988816,
      "grad_norm": 0.8158549666404724,
      "learning_rate": 4.29932933286269e-06,
      "loss": 1.6356,
      "step": 4550
    },
    {
      "epoch": 2.371415566681839,
      "grad_norm": 0.9203881621360779,
      "learning_rate": 4.264031062477939e-06,
      "loss": 1.7344,
      "step": 4560
    },
    {
      "epoch": 2.3766174653748617,
      "grad_norm": 0.8162635564804077,
      "learning_rate": 4.228732792093187e-06,
      "loss": 1.7321,
      "step": 4570
    },
    {
      "epoch": 2.381819364067885,
      "grad_norm": 0.9801768660545349,
      "learning_rate": 4.193434521708437e-06,
      "loss": 1.5834,
      "step": 4580
    },
    {
      "epoch": 2.387021262760908,
      "grad_norm": 0.8824310302734375,
      "learning_rate": 4.1581362513236855e-06,
      "loss": 1.7028,
      "step": 4590
    },
    {
      "epoch": 2.3922231614539307,
      "grad_norm": 0.9205601811408997,
      "learning_rate": 4.122837980938934e-06,
      "loss": 1.7341,
      "step": 4600
    },
    {
      "epoch": 2.397425060146954,
      "grad_norm": 1.0158400535583496,
      "learning_rate": 4.087539710554183e-06,
      "loss": 1.7137,
      "step": 4610
    },
    {
      "epoch": 2.4026269588399765,
      "grad_norm": 0.7676610350608826,
      "learning_rate": 4.052241440169432e-06,
      "loss": 1.5687,
      "step": 4620
    },
    {
      "epoch": 2.4078288575329996,
      "grad_norm": 0.7075480818748474,
      "learning_rate": 4.016943169784681e-06,
      "loss": 1.5982,
      "step": 4630
    },
    {
      "epoch": 2.4130307562260223,
      "grad_norm": 1.0082616806030273,
      "learning_rate": 3.98164489939993e-06,
      "loss": 1.6807,
      "step": 4640
    },
    {
      "epoch": 2.4182326549190454,
      "grad_norm": 0.7203342318534851,
      "learning_rate": 3.946346629015178e-06,
      "loss": 1.6855,
      "step": 4650
    },
    {
      "epoch": 2.4234345536120685,
      "grad_norm": 0.6919451355934143,
      "learning_rate": 3.911048358630428e-06,
      "loss": 1.6851,
      "step": 4660
    },
    {
      "epoch": 2.428636452305091,
      "grad_norm": 0.8254148364067078,
      "learning_rate": 3.875750088245676e-06,
      "loss": 1.6654,
      "step": 4670
    },
    {
      "epoch": 2.4338383509981143,
      "grad_norm": 1.0025789737701416,
      "learning_rate": 3.840451817860925e-06,
      "loss": 1.6383,
      "step": 4680
    },
    {
      "epoch": 2.4390402496911374,
      "grad_norm": 0.9021934270858765,
      "learning_rate": 3.805153547476174e-06,
      "loss": 1.6155,
      "step": 4690
    },
    {
      "epoch": 2.44424214838416,
      "grad_norm": 0.7203036546707153,
      "learning_rate": 3.7698552770914228e-06,
      "loss": 1.6768,
      "step": 4700
    },
    {
      "epoch": 2.449444047077183,
      "grad_norm": 0.7092143297195435,
      "learning_rate": 3.734557006706672e-06,
      "loss": 1.6515,
      "step": 4710
    },
    {
      "epoch": 2.4546459457702063,
      "grad_norm": 0.8478541970252991,
      "learning_rate": 3.6992587363219205e-06,
      "loss": 1.7237,
      "step": 4720
    },
    {
      "epoch": 2.459847844463229,
      "grad_norm": 0.7957504391670227,
      "learning_rate": 3.663960465937169e-06,
      "loss": 1.6872,
      "step": 4730
    },
    {
      "epoch": 2.465049743156252,
      "grad_norm": 0.9015481472015381,
      "learning_rate": 3.6286621955524182e-06,
      "loss": 1.6639,
      "step": 4740
    },
    {
      "epoch": 2.470251641849275,
      "grad_norm": 0.931650698184967,
      "learning_rate": 3.5933639251676673e-06,
      "loss": 1.6742,
      "step": 4750
    },
    {
      "epoch": 2.475453540542298,
      "grad_norm": 0.8041266798973083,
      "learning_rate": 3.5580656547829155e-06,
      "loss": 1.6692,
      "step": 4760
    },
    {
      "epoch": 2.480655439235321,
      "grad_norm": 0.8821403384208679,
      "learning_rate": 3.5227673843981646e-06,
      "loss": 1.7327,
      "step": 4770
    },
    {
      "epoch": 2.4858573379283437,
      "grad_norm": 0.6963825821876526,
      "learning_rate": 3.4874691140134137e-06,
      "loss": 1.6351,
      "step": 4780
    },
    {
      "epoch": 2.491059236621367,
      "grad_norm": 0.7621251344680786,
      "learning_rate": 3.4521708436286627e-06,
      "loss": 1.7225,
      "step": 4790
    },
    {
      "epoch": 2.4962611353143895,
      "grad_norm": 1.0532392263412476,
      "learning_rate": 3.4168725732439114e-06,
      "loss": 1.6775,
      "step": 4800
    },
    {
      "epoch": 2.5014630340074127,
      "grad_norm": 0.7780202627182007,
      "learning_rate": 3.38157430285916e-06,
      "loss": 1.7198,
      "step": 4810
    },
    {
      "epoch": 2.5066649327004358,
      "grad_norm": 0.7048164010047913,
      "learning_rate": 3.346276032474409e-06,
      "loss": 1.6539,
      "step": 4820
    },
    {
      "epoch": 2.5118668313934585,
      "grad_norm": 0.835614800453186,
      "learning_rate": 3.3109777620896577e-06,
      "loss": 1.5643,
      "step": 4830
    },
    {
      "epoch": 2.5170687300864816,
      "grad_norm": 1.2233163118362427,
      "learning_rate": 3.275679491704907e-06,
      "loss": 1.7081,
      "step": 4840
    },
    {
      "epoch": 2.5222706287795047,
      "grad_norm": 0.6294671297073364,
      "learning_rate": 3.240381221320156e-06,
      "loss": 1.624,
      "step": 4850
    },
    {
      "epoch": 2.5274725274725274,
      "grad_norm": 0.7397772669792175,
      "learning_rate": 3.205082950935404e-06,
      "loss": 1.7653,
      "step": 4860
    },
    {
      "epoch": 2.5326744261655505,
      "grad_norm": 0.7329994440078735,
      "learning_rate": 3.169784680550653e-06,
      "loss": 1.6207,
      "step": 4870
    },
    {
      "epoch": 2.5378763248585736,
      "grad_norm": 0.7453497648239136,
      "learning_rate": 3.1344864101659023e-06,
      "loss": 1.6416,
      "step": 4880
    },
    {
      "epoch": 2.5430782235515963,
      "grad_norm": 0.8718213438987732,
      "learning_rate": 3.099188139781151e-06,
      "loss": 1.752,
      "step": 4890
    },
    {
      "epoch": 2.5482801222446194,
      "grad_norm": 0.6948633790016174,
      "learning_rate": 3.0638898693963996e-06,
      "loss": 1.5582,
      "step": 4900
    },
    {
      "epoch": 2.553482020937642,
      "grad_norm": 0.660642147064209,
      "learning_rate": 3.0285915990116486e-06,
      "loss": 1.6551,
      "step": 4910
    },
    {
      "epoch": 2.558683919630665,
      "grad_norm": 0.9025329351425171,
      "learning_rate": 2.9932933286268973e-06,
      "loss": 1.6364,
      "step": 4920
    },
    {
      "epoch": 2.563885818323688,
      "grad_norm": 0.9801040887832642,
      "learning_rate": 2.9579950582421463e-06,
      "loss": 1.5936,
      "step": 4930
    },
    {
      "epoch": 2.569087717016711,
      "grad_norm": 0.7528665661811829,
      "learning_rate": 2.9226967878573954e-06,
      "loss": 1.6295,
      "step": 4940
    },
    {
      "epoch": 2.574289615709734,
      "grad_norm": 0.794322669506073,
      "learning_rate": 2.8873985174726445e-06,
      "loss": 1.7436,
      "step": 4950
    },
    {
      "epoch": 2.579491514402757,
      "grad_norm": 0.7128496766090393,
      "learning_rate": 2.8521002470878927e-06,
      "loss": 1.5615,
      "step": 4960
    },
    {
      "epoch": 2.58469341309578,
      "grad_norm": 0.6963550448417664,
      "learning_rate": 2.8168019767031418e-06,
      "loss": 1.5618,
      "step": 4970
    },
    {
      "epoch": 2.589895311788803,
      "grad_norm": 0.7061228156089783,
      "learning_rate": 2.781503706318391e-06,
      "loss": 1.6361,
      "step": 4980
    },
    {
      "epoch": 2.5950972104818257,
      "grad_norm": 0.8355539441108704,
      "learning_rate": 2.7462054359336395e-06,
      "loss": 1.6933,
      "step": 4990
    },
    {
      "epoch": 2.600299109174849,
      "grad_norm": 0.7822127342224121,
      "learning_rate": 2.710907165548888e-06,
      "loss": 1.5795,
      "step": 5000
    },
    {
      "epoch": 2.605501007867872,
      "grad_norm": 0.7039731740951538,
      "learning_rate": 2.6756088951641372e-06,
      "loss": 1.6662,
      "step": 5010
    },
    {
      "epoch": 2.6107029065608947,
      "grad_norm": 0.8944794535636902,
      "learning_rate": 2.640310624779386e-06,
      "loss": 1.7631,
      "step": 5020
    },
    {
      "epoch": 2.6159048052539178,
      "grad_norm": 0.6453974843025208,
      "learning_rate": 2.605012354394635e-06,
      "loss": 1.6172,
      "step": 5030
    },
    {
      "epoch": 2.621106703946941,
      "grad_norm": 0.9824366569519043,
      "learning_rate": 2.569714084009884e-06,
      "loss": 1.6357,
      "step": 5040
    },
    {
      "epoch": 2.6263086026399636,
      "grad_norm": 0.9075677394866943,
      "learning_rate": 2.5344158136251322e-06,
      "loss": 1.6329,
      "step": 5050
    },
    {
      "epoch": 2.6315105013329867,
      "grad_norm": 0.8142220377922058,
      "learning_rate": 2.4991175432403813e-06,
      "loss": 1.6595,
      "step": 5060
    },
    {
      "epoch": 2.6367124000260094,
      "grad_norm": 0.7858737111091614,
      "learning_rate": 2.4638192728556304e-06,
      "loss": 1.7186,
      "step": 5070
    },
    {
      "epoch": 2.6419142987190325,
      "grad_norm": 1.0493284463882446,
      "learning_rate": 2.428521002470879e-06,
      "loss": 1.7132,
      "step": 5080
    },
    {
      "epoch": 2.647116197412055,
      "grad_norm": 0.894524335861206,
      "learning_rate": 2.3932227320861277e-06,
      "loss": 1.772,
      "step": 5090
    },
    {
      "epoch": 2.6523180961050783,
      "grad_norm": 0.950188934803009,
      "learning_rate": 2.3579244617013768e-06,
      "loss": 1.7263,
      "step": 5100
    },
    {
      "epoch": 2.6575199947981014,
      "grad_norm": 1.012962818145752,
      "learning_rate": 2.322626191316626e-06,
      "loss": 1.5655,
      "step": 5110
    },
    {
      "epoch": 2.662721893491124,
      "grad_norm": 0.6791977882385254,
      "learning_rate": 2.2873279209318745e-06,
      "loss": 1.5934,
      "step": 5120
    },
    {
      "epoch": 2.667923792184147,
      "grad_norm": 0.7909505367279053,
      "learning_rate": 2.2520296505471235e-06,
      "loss": 1.7206,
      "step": 5130
    },
    {
      "epoch": 2.6731256908771703,
      "grad_norm": 0.7700967788696289,
      "learning_rate": 2.216731380162372e-06,
      "loss": 1.6402,
      "step": 5140
    },
    {
      "epoch": 2.678327589570193,
      "grad_norm": 0.7102240324020386,
      "learning_rate": 2.1814331097776213e-06,
      "loss": 1.6291,
      "step": 5150
    },
    {
      "epoch": 2.683529488263216,
      "grad_norm": 0.6928184032440186,
      "learning_rate": 2.14613483939287e-06,
      "loss": 1.6257,
      "step": 5160
    },
    {
      "epoch": 2.6887313869562393,
      "grad_norm": 0.798629641532898,
      "learning_rate": 2.1108365690081186e-06,
      "loss": 1.6428,
      "step": 5170
    },
    {
      "epoch": 2.693933285649262,
      "grad_norm": 0.9077395796775818,
      "learning_rate": 2.0755382986233676e-06,
      "loss": 1.6492,
      "step": 5180
    },
    {
      "epoch": 2.699135184342285,
      "grad_norm": 0.637334942817688,
      "learning_rate": 2.0402400282386163e-06,
      "loss": 1.5602,
      "step": 5190
    },
    {
      "epoch": 2.7043370830353077,
      "grad_norm": 0.7809649705886841,
      "learning_rate": 2.0049417578538654e-06,
      "loss": 1.6735,
      "step": 5200
    },
    {
      "epoch": 2.709538981728331,
      "grad_norm": 0.6599681377410889,
      "learning_rate": 1.969643487469114e-06,
      "loss": 1.6051,
      "step": 5210
    },
    {
      "epoch": 2.7147408804213535,
      "grad_norm": 0.9471590518951416,
      "learning_rate": 1.934345217084363e-06,
      "loss": 1.7811,
      "step": 5220
    },
    {
      "epoch": 2.7199427791143767,
      "grad_norm": 0.9973704218864441,
      "learning_rate": 1.899046946699612e-06,
      "loss": 1.6702,
      "step": 5230
    },
    {
      "epoch": 2.7251446778073998,
      "grad_norm": 0.7785377502441406,
      "learning_rate": 1.8637486763148608e-06,
      "loss": 1.6819,
      "step": 5240
    },
    {
      "epoch": 2.7303465765004225,
      "grad_norm": 1.074263572692871,
      "learning_rate": 1.8284504059301094e-06,
      "loss": 1.7024,
      "step": 5250
    },
    {
      "epoch": 2.7355484751934456,
      "grad_norm": 1.3525222539901733,
      "learning_rate": 1.7931521355453585e-06,
      "loss": 1.5722,
      "step": 5260
    },
    {
      "epoch": 2.7407503738864687,
      "grad_norm": 0.91996830701828,
      "learning_rate": 1.7578538651606072e-06,
      "loss": 1.7511,
      "step": 5270
    },
    {
      "epoch": 2.7459522725794914,
      "grad_norm": 1.010905385017395,
      "learning_rate": 1.722555594775856e-06,
      "loss": 1.6821,
      "step": 5280
    },
    {
      "epoch": 2.7511541712725145,
      "grad_norm": 1.204552173614502,
      "learning_rate": 1.687257324391105e-06,
      "loss": 1.7409,
      "step": 5290
    },
    {
      "epoch": 2.7563560699655376,
      "grad_norm": 0.6836267113685608,
      "learning_rate": 1.6519590540063537e-06,
      "loss": 1.6052,
      "step": 5300
    },
    {
      "epoch": 2.7615579686585603,
      "grad_norm": 0.8835717439651489,
      "learning_rate": 1.6166607836216028e-06,
      "loss": 1.6048,
      "step": 5310
    },
    {
      "epoch": 2.7667598673515834,
      "grad_norm": 1.1075226068496704,
      "learning_rate": 1.5813625132368515e-06,
      "loss": 1.6151,
      "step": 5320
    },
    {
      "epoch": 2.7719617660446065,
      "grad_norm": 0.8561192154884338,
      "learning_rate": 1.5460642428521003e-06,
      "loss": 1.7171,
      "step": 5330
    },
    {
      "epoch": 2.777163664737629,
      "grad_norm": 0.8250409960746765,
      "learning_rate": 1.5107659724673494e-06,
      "loss": 1.6155,
      "step": 5340
    },
    {
      "epoch": 2.7823655634306523,
      "grad_norm": 0.7079986929893494,
      "learning_rate": 1.475467702082598e-06,
      "loss": 1.7316,
      "step": 5350
    },
    {
      "epoch": 2.787567462123675,
      "grad_norm": 0.6811255216598511,
      "learning_rate": 1.4401694316978467e-06,
      "loss": 1.6213,
      "step": 5360
    },
    {
      "epoch": 2.792769360816698,
      "grad_norm": 0.6549342274665833,
      "learning_rate": 1.4048711613130958e-06,
      "loss": 1.6515,
      "step": 5370
    },
    {
      "epoch": 2.797971259509721,
      "grad_norm": 0.8538458347320557,
      "learning_rate": 1.3695728909283446e-06,
      "loss": 1.6307,
      "step": 5380
    },
    {
      "epoch": 2.803173158202744,
      "grad_norm": 0.7118584513664246,
      "learning_rate": 1.3342746205435935e-06,
      "loss": 1.5835,
      "step": 5390
    },
    {
      "epoch": 2.808375056895767,
      "grad_norm": 0.704449474811554,
      "learning_rate": 1.2989763501588423e-06,
      "loss": 1.6859,
      "step": 5400
    },
    {
      "epoch": 2.8135769555887897,
      "grad_norm": 0.7498912811279297,
      "learning_rate": 1.263678079774091e-06,
      "loss": 1.7154,
      "step": 5410
    },
    {
      "epoch": 2.818778854281813,
      "grad_norm": 0.7014117240905762,
      "learning_rate": 1.22837980938934e-06,
      "loss": 1.6894,
      "step": 5420
    },
    {
      "epoch": 2.823980752974836,
      "grad_norm": 1.0584286451339722,
      "learning_rate": 1.193081539004589e-06,
      "loss": 1.687,
      "step": 5430
    },
    {
      "epoch": 2.8291826516678587,
      "grad_norm": 0.7608608603477478,
      "learning_rate": 1.1577832686198378e-06,
      "loss": 1.5601,
      "step": 5440
    },
    {
      "epoch": 2.8343845503608818,
      "grad_norm": 0.776145339012146,
      "learning_rate": 1.1224849982350866e-06,
      "loss": 1.7174,
      "step": 5450
    },
    {
      "epoch": 2.839586449053905,
      "grad_norm": 1.0989232063293457,
      "learning_rate": 1.0871867278503353e-06,
      "loss": 1.6485,
      "step": 5460
    },
    {
      "epoch": 2.8447883477469276,
      "grad_norm": 0.91346675157547,
      "learning_rate": 1.0518884574655841e-06,
      "loss": 1.7657,
      "step": 5470
    },
    {
      "epoch": 2.8499902464399507,
      "grad_norm": 0.9152262806892395,
      "learning_rate": 1.0165901870808332e-06,
      "loss": 1.5595,
      "step": 5480
    },
    {
      "epoch": 2.8551921451329734,
      "grad_norm": 0.8706269860267639,
      "learning_rate": 9.81291916696082e-07,
      "loss": 1.6201,
      "step": 5490
    },
    {
      "epoch": 2.8603940438259965,
      "grad_norm": 0.9933818578720093,
      "learning_rate": 9.459936463113307e-07,
      "loss": 1.7375,
      "step": 5500
    },
    {
      "epoch": 2.865595942519019,
      "grad_norm": 0.764427125453949,
      "learning_rate": 9.106953759265797e-07,
      "loss": 1.6148,
      "step": 5510
    },
    {
      "epoch": 2.8707978412120423,
      "grad_norm": 0.8036413788795471,
      "learning_rate": 8.753971055418286e-07,
      "loss": 1.6031,
      "step": 5520
    },
    {
      "epoch": 2.8759997399050654,
      "grad_norm": 0.8081821799278259,
      "learning_rate": 8.400988351570774e-07,
      "loss": 1.5392,
      "step": 5530
    },
    {
      "epoch": 2.881201638598088,
      "grad_norm": 0.9773523211479187,
      "learning_rate": 8.048005647723262e-07,
      "loss": 1.6274,
      "step": 5540
    },
    {
      "epoch": 2.886403537291111,
      "grad_norm": 0.6930558085441589,
      "learning_rate": 7.69502294387575e-07,
      "loss": 1.7521,
      "step": 5550
    },
    {
      "epoch": 2.8916054359841343,
      "grad_norm": 0.9435328245162964,
      "learning_rate": 7.342040240028239e-07,
      "loss": 1.6483,
      "step": 5560
    },
    {
      "epoch": 2.896807334677157,
      "grad_norm": 0.5682734847068787,
      "learning_rate": 6.989057536180729e-07,
      "loss": 1.7514,
      "step": 5570
    },
    {
      "epoch": 2.90200923337018,
      "grad_norm": 0.8338219523429871,
      "learning_rate": 6.636074832333216e-07,
      "loss": 1.5804,
      "step": 5580
    },
    {
      "epoch": 2.9072111320632033,
      "grad_norm": 0.8195462822914124,
      "learning_rate": 6.283092128485705e-07,
      "loss": 1.6532,
      "step": 5590
    },
    {
      "epoch": 2.912413030756226,
      "grad_norm": 0.7939306497573853,
      "learning_rate": 5.930109424638193e-07,
      "loss": 1.61,
      "step": 5600
    }
  ],
  "logging_steps": 10,
  "max_steps": 5766,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4397992023083418e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
